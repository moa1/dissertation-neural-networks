#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
fix-cm
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing onehalf
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: replace the 
\begin_inset Quotes eld
\end_inset

|
\begin_inset Quotes erd
\end_inset

 in all conditional probabilities 
\begin_inset Formula $P(A|B)$
\end_inset

 with the 
\backslash
mid sign, e.g.
 
\begin_inset Formula $P(A\mid B)$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: in all formulas, replace brackets near a sum sign (as in 
\begin_inset Formula $\sum_{i}(\frac{a}{b})$
\end_inset

) with large brackets (key 
\begin_inset Quotes eld
\end_inset

Alt+m (
\begin_inset Quotes erd
\end_inset

): 
\begin_inset Formula $\sum_{i}\left(\frac{a}{b}\right)$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Ich glaube ich sollte die model-beschreibungen (directed/undirected
 graphical, RBM, DBN) immer gleich strukturieren: 1.
 structure (i.e.
 die nodes und weights erklären) 2.
 How to generate data from the model 3.
 How to train a model so that it fits data.
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Notation
\end_layout

\begin_layout Description
Random
\begin_inset space ~
\end_inset

variable,
\begin_inset space ~
\end_inset

Node Random variables and nodes are written upper-case.
 For example: 
\begin_inset Formula $X$
\end_inset

 or 
\begin_inset Formula $N_{4}$
\end_inset

.
\end_layout

\begin_layout Description
Value,
\begin_inset space ~
\end_inset

Normal
\begin_inset space ~
\end_inset

variable The value of a random variable and a normal variable are written
 lower-case.
 For example, the value of random variable 
\begin_inset Formula $X$
\end_inset

 is written 
\begin_inset Formula $x$
\end_inset

, and 
\begin_inset Formula $i$
\end_inset

 is a normal variable.
\end_layout

\begin_layout Description
Vector,
\begin_inset space ~
\end_inset

Set Vectors or sets are written in bold font.
 For example, the vector 
\begin_inset Formula $\mathbf{X}$
\end_inset

 could represent the random variables 
\begin_inset Formula $\{X_{1},X_{2},X_{3}\}$
\end_inset

.
 And the vector 
\begin_inset Formula $\mathbf{x}$
\end_inset

 could mean the values 
\begin_inset Formula $\{x_{1},x_{2},x_{3}\}$
\end_inset

 of the variables 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: At the end of the manuscript, I could add a list of 
\emph on
emphasized 
\emph default
terms introduced, together with the page number they were introduced on.
 Die emphasized Terms suche ich wahrscheinlich am besten im LyX-Quelltext.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Machine Learning
\end_layout

\begin_layout Standard
(TODO: Definition of supervised, unsupervised, and semi-supervised learning.)
\end_layout

\begin_layout Paragraph
Generative and Discriminative Models
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I'm not sure this belongs here, but I should introduce the concept
 of a 
\begin_inset Quotes eld
\end_inset

Generative Model
\begin_inset Quotes erd
\end_inset

 to be able to refer to it later when introducing Deep Belief Networks from
 RBMs.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
An often-cited quote by 
\begin_inset CommandInset citation
LatexCommand cite
key "Vapnik1998"

\end_inset

 is: 
\begin_inset Quotes eld
\end_inset

If you possess a restricted amount of information for solving some problem,
 try to solve the problem directly and never solve a more general problem
 as an intermediate step.
 It is possible that the available information is sufficient for a direct
 solution but is insufficient for solving a more general intermediate problem.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
A generative model is such a more general problem: its aim is to model the
 input data set such that hypothetical samples can be generated from the
 model which might as well be found in the original input data set.
\end_layout

\begin_layout Standard
A discriminative model on the other hand receives the input samples and
 models the desired output values from these input samples.
 Usually the desired output values have much lower dimension than the input
 samples.
\end_layout

\begin_layout Standard
An advantage of a generative over a discriminative model is that its parameters
 are constrained by the number of bits required to encode the training samples,
 while the parameters of a discriminative model are only constrained by
 the number of bits required to encode the label.
\end_layout

\begin_layout Section
Graphical Models
\end_layout

\begin_layout Subsection
Graphs
\end_layout

\begin_layout Standard
In the following we will define some terms having to do with graphs.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I think I should write nodes in upper-case in the whole document.
 This is logical since I interchangeably refer to both nodes and random
 variables as the same entity, and random variables are upper-case.
 So write 
\begin_inset Formula $\mathbf{E}\ni e=(N_{1},N_{2})$
\end_inset

 below.
\end_layout

\begin_layout Plain Layout
TODO: I also should write edges upper-case since they are sets with two
 elements, and sets are written upper-case.
 Do this in the whole document.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A 
\emph on
graph
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
graph
\end_layout

\end_inset


\emph on
 
\emph default
is a tuple 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 of nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

 and edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

.
 An 
\emph on
edge
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
edge
\end_layout

\end_inset

 
\begin_inset Formula $\mathbf{E}\ni E=(N_{1},N_{2})$
\end_inset

 consists of a pair of nodes 
\begin_inset Formula $N_{1}$
\end_inset

 and 
\begin_inset Formula $N_{2}$
\end_inset

.
 Two nodes 
\begin_inset Formula $N_{1}$
\end_inset

 and 
\begin_inset Formula $N_{2}$
\end_inset

 connected by an edge are called 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
neighbor
\end_layout

\end_inset


\emph on
neighbors
\emph default
.
 A 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
complete graph
\end_layout

\end_inset


\emph on
complete graph 
\emph default
is a graph where there exists an edge 
\begin_inset Formula $E=(N_{1},N_{2})$
\end_inset

 for every distinct pair of nodes 
\begin_inset Formula $\mathbf{N}\ni N_{1}\neq N_{2}\in\mathbf{N}$
\end_inset

.
\end_layout

\begin_layout Standard
An edge can be 
\emph on
directed
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
directed edge
\end_layout

\end_inset

 or 
\emph on
undirected
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
undirected edge
\end_layout

\end_inset

, which means that the edge 
\begin_inset Formula $(N_{1},N_{2})$
\end_inset

 is either distinct from the edge 
\begin_inset Formula $(N_{2},N_{1})$
\end_inset

 or they are the same.
 If all edges of a graph are directed, then the graph is called a 
\emph on
directed graph
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
directed graph
\end_layout

\end_inset

; if all edges are undirected, then the graph is called an 
\emph on
undirected graph
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
undirected graph
\end_layout

\end_inset

.
 In a directed edge 
\begin_inset Formula $E=(P,C)$
\end_inset

, also written as 
\begin_inset Formula $P\rightarrow C$
\end_inset

, 
\begin_inset Formula $P$
\end_inset

 is called the 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
parent
\end_layout

\end_inset


\emph on
parent
\emph default
 and 
\begin_inset Formula $C$
\end_inset

 the 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
child
\end_layout

\end_inset


\emph on
child
\emph default
.
\end_layout

\begin_layout Standard
A 
\emph on
path
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
path
\end_layout

\end_inset

 is an ordered list of edges 
\begin_inset Formula $\mathbf{P}=[E_{1},E_{2},\dots,E_{n}]$
\end_inset

, so that the child of the previous edge is the parent of the next edge:
 If 
\begin_inset Formula $E_{i}=(P_{i},C_{i})$
\end_inset

 and 
\begin_inset Formula $E_{i+1}=(P_{i+1},C_{i+1})$
\end_inset

, then 
\begin_inset Formula $C_{i}=P_{i+1}$
\end_inset

.
 In the path 
\begin_inset Formula $\mathbf{P}$
\end_inset

, 
\begin_inset Formula $P_{p}$
\end_inset

 is called 
\emph on
ancestor
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
ancestor
\end_layout

\end_inset

 of 
\begin_inset Formula $C_{c}$
\end_inset

 if 
\begin_inset Formula $p\leq c$
\end_inset

, and 
\begin_inset Formula $C_{c}$
\end_inset

 is called  
\begin_inset Index idx
status open

\begin_layout Plain Layout
descendant
\end_layout

\end_inset


\emph on
descendant 
\emph default
of 
\begin_inset Formula $P_{p}$
\end_inset

 if 
\begin_inset Formula $p\leq c$
\end_inset

.
 If the child 
\begin_inset Formula $C_{j}$
\end_inset

 of any edge 
\begin_inset Formula $E_{j}$
\end_inset

 in 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is equal to the parent 
\begin_inset Formula $P_{i}$
\end_inset

 of the same or a previous edge (i.e.
 
\begin_inset Formula $i\leq j$
\end_inset

), then the sub-path 
\begin_inset Formula $\mathbf{C}=[(P_{i},C_{i}),(P_{i+1},C_{i+1}),\dots,(P_{j},C_{j})]$
\end_inset

 is called a 
\begin_inset Index idx
status open

\begin_layout Plain Layout
cycle
\end_layout

\end_inset


\emph on
cycle
\emph default
.
\end_layout

\begin_layout Standard
A 
\emph on
directed acyclic graph
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
directed acyclic graph
\end_layout

\end_inset


\emph on
 
\emph default
(DAG
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
DAG
\end_layout

\end_inset

) is a directed graph that does not contain directed cycles.
\end_layout

\begin_layout Standard
A 
\emph on
clique
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
clique
\end_layout

\end_inset


\emph on
 
\emph default
in an undirected graph is a subset of nodes 
\begin_inset Formula $\mathbf{N_{C}}\subset\mathbf{N}$
\end_inset

, such that every pair of nodes in the clique 
\begin_inset Formula $N_{1},N_{2}\in\mathbf{N_{C}}$
\end_inset

 is an edge in the graph: 
\begin_inset Formula $(N_{1},N_{2})\in\mathbf{E}$
\end_inset

.
 A 
\emph on
maximal clique
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
maximal clique
\end_layout

\end_inset

 is a clique where there are no edges that can be added to it so that the
 resulting subset of nodes is still a clique.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: add definition of 
\begin_inset Quotes eld
\end_inset

separate
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A set of nodes 
\begin_inset Formula $\mathbf{N_{A}}\subset\mathbf{N}$
\end_inset

 is 
\emph on
separated
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
separation of nodes
\end_layout

\end_inset


\emph on
 
\emph default
from a set of nodes 
\begin_inset Formula $\mathbf{N_{B}}\subset\mathbf{N}$
\end_inset

 by a set of nodes 
\begin_inset Formula $\mathbf{N_{S}}\subset\mathbf{N}$
\end_inset

, if it is impossible to go (along the edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

 of the graph) from a node 
\begin_inset Formula $N_{1}\in\mathbf{N_{A}}$
\end_inset

 to a node 
\begin_inset Formula $N_{2}\in\mathbf{N_{B}}$
\end_inset

 without passing through any of the nodes in 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

.
\end_layout

\begin_layout Subsection
Graphical Models
\end_layout

\begin_layout Standard
Graphical models are an encoding of a factorizable joint probability distributio
n with the help of a graph.
 There are different types of graphical models, but there are defining elements
 of all graphical models.
 Each node of the graph corresponds to a random variable of the joint probabilit
y distribution.
 The edges of the graph encode the factors of the joint probability distribution.
 The graph, together with probability functions over the structural elements
 of the graph are equivalent to the joint probability distribution.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Vielleicht sollten die beiden Examples (eins für directed und eins für undirecte
d graphical model) jeweils am Anfang der Unterabschnitte 
\begin_inset Quotes eld
\end_inset

(un)directed graphical model
\begin_inset Quotes erd
\end_inset

 stehen.
\end_layout

\begin_layout Plain Layout
TODO: hier muss ein Beispiel mit einer Tabelle einer joint probability distribut
ion stehen.
\end_layout

\begin_layout Plain Layout
TODO: Hier eine Figure mit einem DAG und einem MRF.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Directed and Undirected Graphical Models
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I should write somewhere that the edges in a directed graph encode
 the dependence and independence relationships between the random variables.
 TODO: What do the edges encode in an undirected graph? (Answer: the factorizati
on of the joint.
 (Or, rather cliques than edges encode the factorization).)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the following, we will discuss directed graphical models and undirected
 graphical models.
 Directed graphical models are also called 
\emph on
Bayesian networks
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Bayesian network
\end_layout

\end_inset

, and undirected graphical models are also called 
\emph on
Markov random fields
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Markov random field
\end_layout

\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
There is also an unification of Bayesian networks and Markov random fields,
 i.e.
 a graphical model that can have both directed and undirected edges.
 These networks are called 
\emph on
chain graphs
\emph default
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: reference.
 Referenz zu chain graph ist http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html
 (
\begin_inset Quotes erd
\end_inset

It is possible to have a model with both directed and undirected arcs, which
 is called a chain graph.
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_inset

, or 
\emph on
partially directed acyclic graphs
\emph default
 and are not discussed here.
\end_layout

\end_inset

.
 We will consider only variables with discrete values in the joint probability
 distribution.
\end_layout

\begin_layout Subsubsection
Undirected Graphical Models
\begin_inset CommandInset label
LatexCommand label
name "par:Hammersley-Clifford-theorem"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Hier muß eine formale Definition von 
\begin_inset Quotes eld
\end_inset

undirected graphical model
\begin_inset Quotes erd
\end_inset

 stehen: d.h.
 Erkläre wie man aus dem graph zusammen mit den potentials (die üder die
 Cliquen des Graphs definiert sind) die joint probability distribution berechnen
 kann.
 (das produkt der potentials ist die joint).
\end_layout

\begin_layout Plain Layout
I should at some point write that in undirected graphical models, the probabilit
y is factored into potentials (written 
\begin_inset Formula $\phi$
\end_inset

), where each factor corresponds to a clique in the undirected graph.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We want to encode a joint probability distribution 
\begin_inset Formula $P$
\end_inset

 in an undirected graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

.
 Every random variable corresponds to a node.
 The missing edges encode conditional independencies.
 
\emph on
A complete graph 
\emph default
would encode no conditional independencies.
 However, to minimize computation time we normally want to get a minimal
 graph that still encodes the joint probability distribution faithfully.
 What properties does thee joint probability distribution 
\begin_inset Formula $P$
\end_inset

 have to fulfill and what does the minimal undirected graph 
\begin_inset Formula $G$
\end_inset

 look like?
\end_layout

\begin_layout Paragraph
The Hammersley-Clifford theorem
\end_layout

\begin_layout Standard
The 
\emph on
Hammersley-Clifford theorem
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Hammersley-Clifford theorem
\end_layout

\end_inset


\emph on
 
\emph default
(
\begin_inset CommandInset citation
LatexCommand cite
key "HammersleyClifford1971"

\end_inset

) provides a formal definition.
 It states that when we have a vector of random variables 
\begin_inset Formula $\mathbf{X}=\{X_{1},\dots,X_{n}\}$
\end_inset

, its strictly positive joint probability distribution 
\begin_inset Formula $P(\mathbf{X})$
\end_inset

 with 
\begin_inset Formula $P(\mathbf{x})>0$
\end_inset

 for all possible values 
\begin_inset Formula $\mathbf{x}$
\end_inset

 of 
\series bold

\begin_inset Formula $\mathbf{X}$
\end_inset


\series default
, and an undirected graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 with each node corresponding to a random variable (i.e.
 
\begin_inset Formula $\mathbf{N}=\{X_{1},\dots,X_{n}\}$
\end_inset

), then the following statements are equivalent:
\end_layout

\begin_layout Itemize
\begin_inset Formula $P(\mathbf{X})$
\end_inset

 is a 
\emph on
Gibbs distribution
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Gibbs distribution
\end_layout

\end_inset


\emph on
 
\emph default
that factorizes according to the maximal cliques 
\begin_inset Formula $\mathbf{C_{1}},\dots,\mathbf{C_{m}}$
\end_inset

 in 
\begin_inset Formula $G$
\end_inset

, i.e.
 
\begin_inset Formula $P(\mathbf{X})=\frac{1}{Z}\phi_{1}(\mathbf{C_{1}})\cdot\dots\cdot\phi_{m}(\mathbf{C_{m}})$
\end_inset

 where 
\begin_inset Formula $Z$
\end_inset

 is the 
\emph on
partition function
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
partition function
\end_layout

\end_inset

 such that 
\begin_inset Formula $\sum_{\mathbf{x}}P(\mathbf{X}=\mathbf{x})=1$
\end_inset

, and 
\begin_inset Formula $\phi_{i}(\mathbf{C_{i}})$
\end_inset

 are the 
\emph on
potential functions
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
potential function
\end_layout

\end_inset

, which depend only on the states of the random variables in the clique
 
\begin_inset Formula $\mathbf{C_{i}}=(X_{i_{1}},\dots,X_{i_{n}})$
\end_inset

 and must be positive for all possible states.
\begin_inset Note Note
status open

\begin_layout Plain Layout
On page 21 of the Hammersley-Clifford paper, the authors define the name
 
\begin_inset Quotes eld
\end_inset

light-coloured potential function
\begin_inset Quotes erd
\end_inset

.
 There, they also define 
\begin_inset Quotes eld
\end_inset

Gibbsian ensemble
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset label
LatexCommand label
name "local-Markov-property"

\end_inset

the 
\emph on
local Markov property
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
local Markov property
\end_layout

\end_inset

 
\emph default
holds for the graph 
\begin_inset Formula $G$
\end_inset

 and the joint probability distribution 
\begin_inset Formula $P$
\end_inset

: A node 
\begin_inset Formula $N$
\end_inset

 is conditionally independent from all non-neighbor nodes 
\begin_inset Formula $\mathbf{N}\backslash\mathbf{N_{neighbor}}$
\end_inset

, given the states of the random variables 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: isn't using 
\begin_inset Formula $\mathbf{N}$
\end_inset

 (
\begin_inset Quotes eld
\end_inset

nodes
\begin_inset Quotes erd
\end_inset

) as a synonym for the random variables 
\begin_inset Formula $\mathbf{X}$
\end_inset

 confusing? Yes it is confusing.
 I will use only 
\begin_inset Formula $N$
\end_inset

 from now on, because 
\begin_inset Formula $X$
\end_inset

 is overused.
 TODO: replace 
\begin_inset Formula $X$
\end_inset

 by 
\begin_inset Formula $N$
\end_inset

 in the following.
\end_layout

\end_inset


\begin_inset Formula $\mathbf{N_{neighbor}}$
\end_inset

 immediately connected to 
\begin_inset Formula $N$
\end_inset

: 
\begin_inset Formula $P(X_{i}\mid\mathbf{N_{neighbor}})=P(X_{i}|\mathbf{N})$
\end_inset

.
\end_layout

\begin_layout Itemize
the 
\emph on
global Markov property
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
global Markov property
\end_layout

\end_inset


\emph on
 
\emph default
holds for the graph 
\begin_inset Formula $G$
\end_inset

 and the joint probability distribution 
\begin_inset Formula $P$
\end_inset

: Given any disjoint subsets 
\begin_inset Formula $\mathbf{N_{A}},\mathbf{N_{B}},\mathbf{N_{S}}\subset\mathbf{N}$
\end_inset

 where 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

 separates the nodes 
\begin_inset Formula $\mathbf{N_{A}}$
\end_inset

 from the nodes 
\begin_inset Formula $\mathbf{N_{B}}$
\end_inset

, and given the states of the random variables of 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

, the nodes 
\begin_inset Formula $\mathbf{N_{A}}$
\end_inset

 are conditionally independent of the nodes 
\begin_inset Formula $\mathbf{N_{B}}$
\end_inset

: 
\begin_inset Formula $P(\mathbf{N_{A}}\mid\mathbf{N_{S}})=P(\mathbf{N_{A}\mid}\mathbf{N_{S}},\mathbf{N_{B}})$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: insert example graphics with an undirected graph with node names.
 The figure text should denote the maximal cliques text and illustrate the
 local Markov property for a node 
\begin_inset Formula $N$
\end_inset

 and the global Markov property for two nodes 
\begin_inset Formula $N_{1}$
\end_inset

 and 
\begin_inset Formula $N_{2}$
\end_inset

 separated by a set of nodes 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

.
 Maybe also print definitions of the potential functions for the maximal
 cliques (but these are probably too large).
 The graphics could be similar to Figure 2.3 in 
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/graphical model/Koller+al_SRL07.pdf
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This means that when we have a strictly positive joint probability distribution
 
\begin_inset Formula $P$
\end_inset

, we can determine the conditional independencies by considering the local
 or global Markov property, and construct the minimal undirected graph 
\begin_inset Formula $G$
\end_inset

 representing 
\begin_inset Formula $P$
\end_inset

 by starting from the completely connected graph and deleting the edges
 
\begin_inset Formula $E_{12}=(N_{1},N_{2})$
\end_inset

 whose ends are conditionally independent 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: conditionally independent on what? I think that's the crux of being
 NP; we probably have to enumerate all possible separators...?
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
On the other hand, if we have a graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 consisting of a given set of nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

 and edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

, and local conditional probabilities 
\begin_inset Formula $P(N\mid\mathbf{N}_{\mathbf{Parents}})$
\end_inset

 at each node fulfilling the Markov property, then we can derive from that
 the joint probability distribution over all random variables, or equivalently
 over all nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Example of an Undirected Graphical Model
\end_layout

\begin_layout Standard
For example, if there are the three cliques 
\begin_inset Formula $\mathbf{C_{1}}=\{X_{1},X_{2},X_{3}\}$
\end_inset

, 
\begin_inset Formula $\mathbf{C_{2}}=\{X_{3},X_{4}\}$
\end_inset

, and 
\begin_inset Formula $\mathbf{C_{3}}=\{X_{3},X_{5}\}$
\end_inset

, then the joint probability distribution 
\begin_inset Formula $P$
\end_inset

 (also called 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Gibbs distribution
\end_layout

\end_inset

Gibbs distribution) can be written as: 
\begin_inset Formula 
\[
P(X_{1},\dots,X_{5})=\frac{1}{Z}\phi_{1}(\mathbf{C_{1}})\phi_{2}(\mathbf{C_{2}})\phi_{3}(\mathbf{C_{3}})
\]

\end_inset

, where 
\begin_inset Formula $\phi_{1}(\mathbf{C_{1}})=\phi(X_{1},X_{2},X_{3})$
\end_inset

 is the potential function of clique 1 (
\emph on
clique potential
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
clique potential
\end_layout

\end_inset

), and is a function of the 3 random variables 
\begin_inset Formula $X_{1},X_{2},X_{3}$
\end_inset

 in the clique.
 
\begin_inset Formula $Z$
\end_inset

 is the partition function and must normalize the function so that 
\begin_inset Formula $P$
\end_inset

 is a probability: 
\begin_inset Formula 
\[
Z=\sum_{X_{1},\dots,X_{n}}\phi_{1}(\mathbf{C_{1}})\phi_{2}(\mathbf{C_{2}})\phi_{3}(\mathbf{C_{3}})
\]

\end_inset


\end_layout

\begin_layout Standard
In practice, 
\begin_inset Formula $\phi_{1}(X_{1},X_{2},X_{3})$
\end_inset

 can be represented by a table that has, for each possible combination of
 states of the three random variables, a positive real number.
 For example, if each of the three random variables has two states, then
 the table (with 
\begin_inset Formula $2^{3}$
\end_inset

 entries) could look like this:
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{3}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi(X_{1}=x_{1},X_{2}=x_{2},X_{3}=x_{3})$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.124
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.553
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.842
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.258
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Subsubsection
Directed Graphical Models
\end_layout

\begin_layout Standard
Directed graphical models are also called 
\emph on
Bayesian Networks
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Bayesian Networks
\end_layout

\end_inset

 or 
\emph on
Belief Networks
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Belief Networks
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Like undirected graphical models, directed graphical models represent an
 implicit joint probability distribution over all random variables present
 in the model.
 The graph must be directed and acyclic, and each node of the graph is associate
d with a random variable.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: example figure
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A directed graphical model is defined by the directed graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

, a prior probability distribution 
\begin_inset Formula $P(N_{noparents})$
\end_inset

 at the nodes that do not have parents 
\begin_inset Formula $\mathbf{N_{noparents}}$
\end_inset

, and conditional probability distributions 
\begin_inset Formula $P(N_{hasparents}\mid\mathbf{N_{parents}})$
\end_inset

 at the nodes that have parents 
\begin_inset Formula $\mathbf{N_{hasparents}}$
\end_inset

.
 In the latter nodes the conditional probability distribution may only condition
 on its immediate parents, not on distant ancestors.
 The directed graph encodes the set of conditional independencies between
 the random variables: A random variable 
\begin_inset Formula $X$
\end_inset

 of the graph is conditionally independent of all random variables that
 are not descendants of 
\begin_inset Formula $X$
\end_inset

 (i.e.
 
\begin_inset Formula $\mathbf{N}\backslash\mathbf{N_{descendant(\mathbf{\mathrm{X}})}}$
\end_inset

) given the values of the parent variables of 
\begin_inset Formula $X$
\end_inset

 (this is called the 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
local Markov property
\end_layout

\end_inset


\emph on
local Markov property
\emph default
 of directed graphs):
\begin_inset Formula 
\[
X\perp(\mathbf{N}\backslash\mathbf{N_{descendant(\mathrm{X})}})\mid\mathbf{N_{parent(\mathrm{X})}}
\]

\end_inset

.
\end_layout

\begin_layout Standard
In a directed graphical model, the random variables 
\begin_inset Formula $\mathbf{N}$
\end_inset

 can be totally ordered such that 
\begin_inset Formula $N_{i}$
\end_inset

 comes before 
\begin_inset Formula $N_{j}$
\end_inset

 if there is a directed path from 
\begin_inset Formula $N_{i}$
\end_inset

 to 
\begin_inset Formula $N_{j}$
\end_inset

 in the graph, and the order is unspecified if there is no directed path
 between 
\begin_inset Formula $N_{i}$
\end_inset

 and 
\begin_inset Formula $N_{j}$
\end_inset

.
 (This means there are graphs which have more than one compatible ordering,
 for example in the graph 
\begin_inset Formula $A\rightarrow C\leftarrow B$
\end_inset

, the ordering can be 
\begin_inset Formula $A,B,C$
\end_inset

 as well as 
\begin_inset Formula $B,A,C$
\end_inset

.) In the following the ordering is expressed as the subscript 
\begin_inset Formula $i\in\mathbb{N}$
\end_inset

 of the random variable 
\begin_inset Formula $N_{i}$
\end_inset

.
 The node 
\begin_inset Formula $N_{i}$
\end_inset

 has associated with it the conditional probability 
\begin_inset Formula $P(N_{i}=n_{i}|\mathbf{N_{j}}=\mathbf{n_{j}}:\mathbf{j}<i)$
\end_inset

.
 (
\begin_inset Quotes eld
\end_inset

The probability that the random variable 
\begin_inset Formula $N_{i}$
\end_inset

 is equal to 
\begin_inset Formula $n_{i}$
\end_inset

 given that the random variables 
\series bold

\begin_inset Formula $\mathbf{N_{j}}$
\end_inset

 
\series default
are equal to 
\begin_inset Formula $\mathbf{n_{j}}$
\end_inset

 where all subscripts 
\begin_inset Formula $\mathbf{j}$
\end_inset

 fulfill the condition that 
\begin_inset Formula $j<i$
\end_inset

.
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Standard
The joint probability distribution encoded by the graph is
\begin_inset Formula 
\[
P(\mathbf{N})=P(N_{1}=n_{1},N_{2}=n_{2},\dots,N_{n}=n_{n})=\prod_{i=1}^{n}P(N_{i}=n_{i}|\mathbf{N_{j}=n_{j}}:\mathbf{j}<i)
\]

\end_inset

.
\end_layout

\begin_layout Paragraph
Example how to represent the conditional probability distribution
\end_layout

\begin_layout Standard
For example, if the 
\begin_inset Formula $N_{i}$
\end_inset

 can only assume discrete 
\begin_inset Formula $n_{i}$
\end_inset

, the conditional probability distribution can be represented by a table
 with a size exponential in the number of involved nodes.
 When a node has 
\begin_inset Formula $a$
\end_inset

 ancestors, each of which has 
\begin_inset Formula $s$
\end_inset

 possible states, and the node itself also has 
\begin_inset Formula $s$
\end_inset

 possible states, then the table must contain one probability for each of
 the 
\begin_inset Formula $s^{a}*(s-1)$
\end_inset

 possible states.
 (
\begin_inset Formula $s^{a}$
\end_inset

 for the combinations of the values of the ancestors and 
\begin_inset Formula $(s-1)$
\end_inset

 for the values the node itself can assume.)
\end_layout

\begin_layout Subsection
Inference in Graphical Models
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Do 
\begin_inset Formula $\mathbf{K},\mathbf{W},\mathbf{U}$
\end_inset

 have to fulfill some relationship for directed acyclic graphs in the inference
 example below? (For example, does 
\begin_inset Formula $\mathbf{K}$
\end_inset

 have to be a subset of the parents of 
\series bold

\begin_inset Formula $\mathbf{W}$
\end_inset


\series default
?)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Maybe I should explain the algorithm 
\begin_inset Quotes eld
\end_inset

ELIMINATE
\begin_inset Quotes erd
\end_inset

 from 
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/graphical model/inference/jordan.pdf
\begin_inset Quotes erd
\end_inset

 and exercise it for an instance of a directed and undirected graph.
 This would be more systematic than it is now.
\end_layout

\begin_layout Plain Layout
TODO: In the introduction of this section (
\begin_inset Quotes eld
\end_inset

Inference in Graphical Models
\begin_inset Quotes erd
\end_inset

) I should cite the paper 
\begin_inset CommandInset citation
LatexCommand cite
key "ChandrasekaranHarsha2012"

\end_inset

 when stating that inference in graphical models is NP-hard in the general
 case.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Algorithm for Exact Inference on General Graph
\end_layout

\begin_layout Subsubsection
Exact Inference in Directed and in Undirected Graphical Models
\begin_inset CommandInset label
LatexCommand label
name "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset


\end_layout

\begin_layout Standard
A graphical model is a representation of a joint probability distribution.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I'm not sure I know how 
\begin_inset Quotes eld
\end_inset

Inference
\begin_inset Quotes erd
\end_inset

 is defined.
 I should look it up in a book, e.g.
 
\begin_inset Quotes eld
\end_inset

Probabilistic Graphical Model, by Koller and Friedman
\begin_inset Quotes erd
\end_inset

.
 But that book is not downloadable.
\end_layout

\begin_layout Plain Layout
There is a paper, however: http://ai.stanford.edu/~koller/Papers/Koller+al:SRL07.pd
f
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inference in a graphical model is the task of answering a query about the
 joint probability distribution encoded by the graph.
 However, in the general case this takes exponential time.
 An example will illustrate this.
\end_layout

\begin_layout Standard
For example, we might want to infer the probability of a configuration of
 variables when the values of only some of the variables are known.
 This means that we can partition the variables 
\begin_inset Formula $\mathbf{V}$
\end_inset

 of a graphical model into three disjoint groups:
\end_layout

\begin_layout Enumerate
the known variables 
\begin_inset Formula $\mathbf{K}$
\end_inset

,
\end_layout

\begin_layout Enumerate
the unknown variables 
\begin_inset Formula $\mathbf{W}$
\end_inset

 that we want to know the probability distribution of,
\end_layout

\begin_layout Enumerate
the unknown variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

 that we do not care about.
\end_layout

\begin_layout Standard
Let the known values of 
\begin_inset Formula $\mathbf{K}$
\end_inset

 be written 
\series bold

\begin_inset Formula $\mathbf{k}$
\end_inset


\series default
.
 The unknown values of 
\begin_inset Formula $\mathbf{W}$
\end_inset

 are named 
\series bold

\begin_inset Formula $\mathbf{w}$
\end_inset


\series default
, and the values of 
\begin_inset Formula $\mathbf{U}$
\end_inset

, 
\begin_inset Formula $\mathbf{u}$
\end_inset

.
 
\end_layout

\begin_layout Standard
When we want to find the probability of configuration 
\begin_inset Formula $\mathbf{W}=\mathbf{w}$
\end_inset

, given 
\begin_inset Formula $\mathbf{K}=\mathbf{k}$
\end_inset

, we can first write the query in terms of the joint probability distribution.
 After that we marginalize out the unknown variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

 that we do not care about, and condition on 
\begin_inset Formula $\mathbf{K}$
\end_inset

.
 
\begin_inset Formula 
\begin{eqnarray}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k}) & = & \sum_{\mathbf{U}}P(\mathbf{W}=\mathbf{w},\mathbf{U}=\mathbf{u}|\mathbf{K}=\mathbf{k})\nonumber \\
 & = & \sum_{\mathbf{U}}\frac{P(\mathbf{W}=\mathbf{w},\mathbf{U}=\mathbf{u},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\label{eq:Inference in graphical models}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
In the above formula there is a sum over all variables 
\series bold

\begin_inset Formula $\mathbf{U}$
\end_inset


\series default
.
 Writing this out, we obtain: 
\begin_inset Formula 
\begin{eqnarray}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k})\nonumber \\
= & \sum_{\mathbf{U}}\frac{P(\mathbf{W}=\mathbf{w},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\nonumber \\
= & \sum_{U_{1}}\sum_{U_{2}}\cdots\sum_{U_{n}}\frac{P(\mathbf{W}=\mathbf{w},U_{1}=u_{1},U_{2}=u_{2},\dots,U_{n}=u_{n},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\label{eq:Inference in graphical models, written out}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
In the general case (if the joint probability cannot be factorized), this
 nested sum needs 
\begin_inset Formula $O(|\mathbf{u}|^{|\mathbf{U}|})=O(|\mathbf{u}|^{n})$
\end_inset

 operations to compute, where 
\begin_inset Formula $|\mathbf{u}|$
\end_inset

 is the number of possible values a variable 
\begin_inset Formula $U_{i}$
\end_inset

 can have (assuming for simplicity that all random variables 
\begin_inset Formula $U_{i}$
\end_inset

 have the same number of possible values 
\begin_inset Formula $|\mathbf{u}|$
\end_inset

) and 
\begin_inset Formula $|\mathbf{U}|$
\end_inset

 is the number of unknown variables 
\begin_inset Formula $U_{i}$
\end_inset

.
 This is because all possible combinations of variable assignments have
 to be considered.
 Thus, for this naive marginalization run-time is exponential in the number
 of variables, and therefore intractable.
 However, in this example we have not considered the structure of the graph
 at all.
 We can improve run-time in some cases of graphs and for some sets of variables
 
\begin_inset Formula $\mathbf{K}$
\end_inset

, 
\begin_inset Formula $\mathbf{W}$
\end_inset

, 
\begin_inset Formula $\mathbf{U}$
\end_inset

, but in general, exact inference can 
\end_layout

\begin_layout Paragraph
The Junction-tree Algorithm
\end_layout

\begin_layout Standard
The run-time can be shortened by marginalizing variables out as early as
 possible.
 This must be done according to the factorization imposed by the graph structure.
\end_layout

\begin_layout Paragraph
Intractability of Inference
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "ChandrasekaranHarsha2012"

\end_inset

 showed that under some assumptions, 
\emph on
treewidth
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
treewidth
\end_layout

\end_inset

 is the only structural property that ensures polynomial run-time of exact
 inference on arbitrary graphs 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: the paper says on page 1: 
\begin_inset Quotes eld
\end_inset

Among these problems is inference in graphi- cal models, which, as mentioned
 earlier, can be solved in polynomial-time if the treewidth of the underly-
 ing graphs is bounded.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

, given that arbitrary potential functions should be allowed.
\end_layout

\begin_layout Standard
For a triangulated graph, the treewidth is the number of nodes contained
 in the largest clique minus one.
 For a graph of any form, the treewidth is the treewidth of the triangulation
 that minimizes the treewidth.
 For directed acyclic graphs, the number of parents is the critical number
 (also shown by 
\begin_inset CommandInset citation
LatexCommand cite
key "KwisthoutVanderGaag2010"

\end_inset

), since it determines the treewidth of the moralized
\begin_inset Foot
status open

\begin_layout Plain Layout
You obtain a moralized graph from a directed acyclic graph by introducing
 edges between all parents of a node, and then replacing directed edges
 by undirected edges.
\end_layout

\end_inset

 graph.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: stimmt das Folgende? Ich dachte, man könnte das aufgrund der Struktur
 von Formel (1) im Paper sagen, aber glaube gerade, dass das nicht reicht:
 
\begin_inset Quotes eld
\end_inset

For directed graphs, factorization according to the edges of the graph serves
 the purpose of cliques in the proof.
 Thus, the cliques are defined on the moral graph of the directed graph.
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The assumptions of the proof are that 
\begin_inset Formula $\mathbf{NP}\nsubseteq\mathbf{P/poly}$
\end_inset

, which is a version of the 
\begin_inset Formula $\mathbf{NP}\neq\mathbf{P}$
\end_inset

 assumption, and that the grid-minor hypothesis is true.
 (For an explanation of the grid-minor hypothesis, see Section 2.4 in 
\begin_inset CommandInset citation
LatexCommand cite
key "ChandrasekaranHarsha2012"

\end_inset

.)
\end_layout

\begin_layout Standard
If these assumptions are correct then the only way to reduce the computational
 cost of exact inference on a general graph is to reduce
\begin_inset Note Note
status open

\begin_layout Plain Layout
Page 2, section 
\begin_inset Quotes eld
\end_inset

Main Result
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

 the treewidth or choose particularly simple potential functions
\begin_inset Note Note
status open

\begin_layout Plain Layout
Page 2, section 
\begin_inset Quotes eld
\end_inset

Main Result
\begin_inset Quotes erd
\end_inset

: 
\begin_inset Quotes eld
\end_inset

there exists a choice of potential functions ...
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsubsection
Example of Exact Inference in a Directed Graphical Model
\begin_inset CommandInset label
LatexCommand label
name "sub:Example-of-Exact-Inference-in-a-directed-graphical-model"

\end_inset


\end_layout

\begin_layout Standard
Here we show an example how inference in a specific directed graphical model
 is done.
 The directed graphical model shall be composed of several densely connected
 layers, where the nodes within a layer are not connected, and they have
 outgoing directed connections only to nodes in the adjacent layer below.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: insert graphics here that looks like a the directed graph 
\begin_inset Formula $\mathbf{G}\rightarrow\mathbf{H}\rightarrow\mathbf{V}$
\end_inset

, but with individual nodes in 
\begin_inset Formula $\mathbf{G}$
\end_inset

, 
\begin_inset Formula $\mathbf{H}$
\end_inset

, 
\begin_inset Formula $\mathbf{V}$
\end_inset

, and that I can use to explain why inference in a densely connected directed
 graphical model is hard.
\end_layout

\end_inset

When the probability distribution of the parent nodes are known, inferring
 the probability distributions of child nodes is easy: just multiply the
 probability of the parents with the conditional probability of the child.
 Therefore, given the probability distributions of the nodes in the bottom
 layer, we want to infer the probability distributions for all the other
 nodes.
 We want to determine the exact probability distributions, hence the term
 
\begin_inset Quotes eld
\end_inset

exact inference
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
For example let a directed acyclic graph be defined by the following directed
 connections between its nodes: 
\begin_inset Formula $G_{1}\rightarrow H_{1}$
\end_inset

, 
\begin_inset Formula $G_{1}\rightarrow H_{2}$
\end_inset

, 
\begin_inset Formula $G_{2}\rightarrow H_{1}$
\end_inset

, 
\begin_inset Formula $G_{2}\rightarrow H_{2}$
\end_inset

, 
\begin_inset Formula $H_{1}\rightarrow V_{1}$
\end_inset

, 
\begin_inset Formula $H_{1}\rightarrow V_{2}$
\end_inset

, 
\begin_inset Formula $H_{2}\rightarrow V_{1}$
\end_inset

, 
\begin_inset Formula $H_{2}\rightarrow V_{2}$
\end_inset

.
 Furthermore the following conditional probability distributions are given:
 
\begin_inset Formula $P(H_{1}|G_{1},G_{2})$
\end_inset

, 
\begin_inset Formula $P(H_{2}|G_{1},G_{2})$
\end_inset

, 
\begin_inset Formula $P(V_{1}|H_{1},H_{2})$
\end_inset

, 
\begin_inset Formula $P(V_{2}|H_{1},H_{2})$
\end_inset

.
 This defines a directed graphical model.
\end_layout

\begin_layout Standard
Now assume that 
\begin_inset Formula $P(V_{1})$
\end_inset

, 
\begin_inset Formula $P(V_{2})$
\end_inset

 are given and we want to infer 
\begin_inset Formula $P(G_{1})$
\end_inset

, 
\begin_inset Formula $P(G_{2})$
\end_inset

, 
\begin_inset Formula $P(H_{1})$
\end_inset

, 
\begin_inset Formula $P(H_{2})$
\end_inset

.
 Using Bayes' Theorem (
\begin_inset Formula $\mbox{posterior}=\mbox{likelihood}*\mbox{prior}$
\end_inset

) we get:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P(H_{1},H_{2}|V_{1},V_{2}) & = & \frac{P(V_{1},V_{2}|H_{1},H_{2})P(H_{1},H_{2})}{P(V_{1},V_{2})}\\
 & = & \frac{P(V_{1},V_{2}|H_{1},H_{2})P(G_{1})P(G_{2})P(H_{1}\mid G_{1},G_{2})P(H_{2}\mid G_{1},G_{2})}{P(V_{1},V_{2})}\\
 & = & \frac{P(V_{1}|H_{1},H_{2})P(V_{2}|H_{1},H_{2})P(G_{1})P(G_{2})P(H_{1}\mid G_{1},G_{2})P(H_{2}\mid G_{1},G_{2})}{Z}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Z=\sum_{h_{1}}\sum_{h_{2}}P(V_{1}|H_{1}=h_{1},H_{2}=h_{2})P(V_{2}|H_{1}=h_{1},H_{2}=h_{2})P(H_{1}=h_{1},H_{2}=h_{2})
\]

\end_inset


\end_layout

\begin_layout Standard
We can make the last transformation because 
\begin_inset Formula $\ensuremath{V_{1}}$
\end_inset

 and 
\begin_inset Formula $\ensuremath{V_{2}}$
\end_inset

 are independent given 
\begin_inset Formula $\ensuremath{H_{1}},\ensuremath{H_{2}}$
\end_inset

 (local Markov property).
 To determine 
\begin_inset Formula $P(H_{1}|V_{1},V_{2})$
\end_inset

 and 
\begin_inset Formula $P(H_{2}|V_{1},V_{2})$
\end_inset

, we have to marginalize the other variable in 
\begin_inset Formula $\mathbf{H}$
\end_inset

 out:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P(H_{1}|V_{1},V_{2}) & = & \sum_{h_{2}}P(H_{1},H_{2}=h_{2}|V_{1},V_{2})\\
P(H_{2}|V_{1},V_{2}) & = & \sum_{h_{1}}P(H_{1}=h_{1},H_{2}|V_{1},V_{2})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
This does not look too complicated, but note that if there are 
\begin_inset Formula $n$
\end_inset

 binary variables in 
\begin_inset Formula $\mathbf{H}$
\end_inset

, then the computation of 
\begin_inset Formula $P(\mathbf{H}|\mathbf{V})$
\end_inset

 takes 
\begin_inset Formula $O(2^{n-1}n)$
\end_inset

 due to having to marginalize out all variables in 
\begin_inset Formula $\mathbf{H}$
\end_inset

 except one, and this for all variables.
 The phenomenon that leads to this computational problem is called 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
explaining away
\end_layout

\end_inset


\emph on
explaining away
\emph default
.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: 
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/graphical model/explaining_away/pami93.pdf
\begin_inset Quotes erd
\end_inset

 says that explaining away can not only decrease but also INCREASE belief:
 (in the abstract) 
\begin_inset Quotes eld
\end_inset

The opposite of explaining away also can occur, where the confirmation of
 one cause increases belief in another.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Since we now have 
\begin_inset Formula $P(H_{1}|\mathbf{V})$
\end_inset

, using 
\begin_inset Formula $P(H_{1})=\sum_{v_{1}}\sum_{v_{2}}P(H_{1},V_{1}=v_{1},V_{2}=v_{2})$
\end_inset

 and 
\begin_inset Formula $P(H_{1}|V_{1},V_{2})=P(H_{1},V_{1},V_{2})/P(V_{1},V_{2})$
\end_inset

, we can determine 
\begin_inset Formula $P(H_{1})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
P(H_{1}) & = & \sum_{v_{1}}\sum_{v_{2}}P(H_{1}|V_{1}=v_{1},V_{2}=v_{2})P(V_{1}=v_{1},V_{2}=v_{2})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $P(H_{2})$
\end_inset

 can be computed similarly.
 Now that we know 
\begin_inset Formula $P(H_{1})$
\end_inset

 and 
\begin_inset Formula $P(H_{2})$
\end_inset

, we can repeat the steps to determine 
\begin_inset Formula $P(G_{1})$
\end_inset

 and 
\begin_inset Formula $P(G_{2})$
\end_inset

.
 This concludes how to do exact inference in a directed graphical model.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rewrite the following sentence in order to remove 
\begin_inset Quotes eld
\end_inset

belief network
\begin_inset Quotes erd
\end_inset

 that was not introduced yet:
\end_layout

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

However, due to all the involved marginalizations, this procedure becomes
 infeasible in a belief network with more than a few parents per node.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Factorization in Undirected Graphical Models
\end_layout

\begin_layout Standard
In the case of an undirected graphical model, this can be improved by factorizin
g the joint probability into independent sub-joint-probabilities, if possible.
 For example, if the random variables 
\begin_inset Formula $\mathbf{U}=\{U_{1},U_{2},\dots,U_{7}\}$
\end_inset

 can be partitioned into three pairwise independent cliques 
\begin_inset Formula $\mathbf{C_{1}}=\{U_{1},U_{2}\},$
\end_inset

 
\begin_inset Formula $\mathbf{C_{2}}=\{U_{2},U_{3}\}$
\end_inset

, 
\begin_inset Formula $\mathbf{C_{3}}=\{U_{3},U_{4},U_{5}\}$
\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Note that the random variables 
\begin_inset Formula $U$
\end_inset

 overlap between clusters, so that the clusters are connected.
\end_layout

\end_inset

, so that 
\begin_inset Formula $P(\mathbf{U})=P(\mathbf{C_{1}})P(\mathbf{C_{2}})P(\mathbf{C_{3}})$
\end_inset

, then above sum can be written as: 
\begin_inset Formula 
\begin{eqnarray*}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k}) & =\\
 & = & \sum_{\mathbf{C_{1}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{1}}|\mathbf{K}=\mathbf{k})*\\
 &  & \sum_{\mathbf{C_{2}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{2}}|\mathbf{K}=\mathbf{k})*\\
 &  & \sum_{\mathbf{C_{3}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{3}}|\mathbf{K}=\mathbf{k})\\
 & = & \prod_{\mathbf{C}\in\{\mathbf{C_{1}},\mathbf{C_{2}},\mathbf{C_{3}}\}}\sum_{\mathbf{C}}P(\mathbf{W}=\mathbf{w},\mathbf{C}|\mathbf{K}=\mathbf{k})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The runtime of this formula is dominated by the largest clique, and so the
 runtime is 
\begin_inset Formula $O(|\mathbf{u}|^{|\mathbf{C_{l}}|})$
\end_inset

, where 
\begin_inset Formula $\mathbf{C_{l}}$
\end_inset

 is the clique with the largest number of variables in it (in our example
 
\begin_inset Formula $\mathbf{C_{l}}=\mathbf{C_{3}}$
\end_inset

, because 
\begin_inset Formula $|\mathbf{C_{3}}|=3$
\end_inset

, and 
\begin_inset Formula $|\mathbf{C_{1}}|=|\mathbf{C_{2}}|=2$
\end_inset

).
 This is still an exponential run-time.
 Therefore, in practice, the joint probability is approximated, for example
 by Gibbs sampling.
\end_layout

\begin_layout Subsubsection
General Algorithm
\end_layout

\begin_layout Standard
In the following paragraph we summarize the ELIMINATE algorithm from 
\begin_inset CommandInset citation
LatexCommand cite
key "JordanWeiss2002"

\end_inset

.
 This algorithm works for both directed and undirected graphical models
 and computes the marginal probabilities of all nodes.
\end_layout

\begin_layout Subsubsection
Markov Chain
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Bild von einer Markov Chain.
 Evtl.
 von einer Markov Chain, an der ich die verschiedenen Eigenschaften wie
 period, irreducible, etc.
 zeigen kann.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Definitions
\end_layout

\begin_layout Subparagraph
Markov property: Memorylessness
\end_layout

\begin_layout Standard
A 
\emph on
Markov Chain 
\emph default
is a time sequence of random variables 
\begin_inset Formula $X_{t}$
\end_inset

, where 
\begin_inset Formula $t\in\mathbb{N}_{0}$
\end_inset

 denotes the discrete index of time.
 In a Markov Chain, each random variable 
\begin_inset Formula $X_{t}$
\end_inset

 may depend only on the state of the random variable at the immediate previous
 time point 
\begin_inset Formula $t-1$
\end_inset

, i.e.
 
\begin_inset Formula 
\[
P(X_{t}=x_{t}|X_{0}=x_{0},\dots,X_{t-1}=x_{t-1})=P(X_{t}=x_{t}|X_{t-1}=x_{t-1})
\]

\end_inset

must hold for all 
\begin_inset Formula $t\geq1$
\end_inset

.
 This memorylessness is called the 
\emph on
Markov property
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Markov property
\end_layout

\end_inset

.
 In a Markov Chain, possible states 
\begin_inset Formula $x_{t}$
\end_inset

 at each time point are discrete and from the same set 
\begin_inset Formula $\mathbb{S}$
\end_inset

.
 (I.e.
 
\begin_inset Formula $x_{t}\in\mathbb{S}$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.) When the state a Markov Chain is in is not specific to a certain time
 point 
\begin_inset Formula $t$
\end_inset

, we will also use single-letter variables like 
\begin_inset Formula $i\in\mathbb{S}$
\end_inset

 and 
\begin_inset Formula $j\in\mathbb{S}$
\end_inset

 to denote the state, e.g.
 
\begin_inset Formula $X_{1}=i$
\end_inset

.
\end_layout

\begin_layout Subparagraph
Time-homogeneous Markov Chain and Transition Matrix
\end_layout

\begin_layout Standard
A 
\emph on
time-homogeneous Markov Chain
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
time-homogeneous Markov Chain
\end_layout

\end_inset

 is a Markov Chain in which the conditional probability 
\begin_inset Formula $P(X_{t}=x_{t}|X_{t-1}=x_{t-1})$
\end_inset

 is the same for all time points 
\begin_inset Formula $t$
\end_inset

, i.e.
 
\begin_inset Formula 
\[
P(X_{t}=x_{t}|X_{t-1}=x_{t-1})=P(X_{t-1}=x_{t-1}|X_{t-2}=x_{t-2})
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
for all time points 
\begin_inset Formula $t\geq2$
\end_inset

.
 If this is the case, then this conditional probability
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: In the following, do I have to replace 
\begin_inset Formula $p$
\end_inset

 with 
\begin_inset Formula $P$
\end_inset

, because it is a matrix?
\end_layout

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula 
\[
P(X_{t}=j|X_{t-1}=i)\eqqcolon p_{ij}
\]

\end_inset

 is independent of the current time 
\begin_inset Formula $t$
\end_inset

 and can be written as the two-dimensional matrix 
\begin_inset Formula $p$
\end_inset

, called the 
\family default
\series default
\shape default
\size default
\emph on
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
transition matrix
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
transition matrix
\end_layout

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
.
 In the following we will only be dealing with time-homogeneous Markov chains.
\end_layout

\begin_layout Subparagraph
Computing future states from the initial distribution
\end_layout

\begin_layout Standard
It makes sense to talk about the distribution of states a Markov chain can
 have at a certain time point 
\begin_inset Formula $t$
\end_inset

.
 Let it be named the 
\emph on
probability vector
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
probability vector
\end_layout

\end_inset


\emph on
 
\emph default

\begin_inset Formula $d^{(t)}$
\end_inset

, a row vector with its length equal to 
\begin_inset Formula $|\mathbb{S}|$
\end_inset

 (the number of different possible states of the random variables 
\begin_inset Formula $X_{t}$
\end_inset

) and its entry 
\begin_inset Formula $d_{i}^{(t)}=P(X_{t}=x_{i})$
\end_inset

 equal to the probability of 
\begin_inset Formula $X_{t}$
\end_inset

 having state 
\begin_inset Formula $x_{i}$
\end_inset

.
 (This means 
\begin_inset Formula $\sum_{i}d_{i}^{(t)}=1$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.) The distribution at the next time point 
\begin_inset Formula $t+1$
\end_inset

 can be computed by matrix multiplication from 
\begin_inset Formula $d^{(t)}$
\end_inset

 and the transition matrix 
\begin_inset Formula $(p_{ji})$
\end_inset

: 
\begin_inset Formula 
\[
d^{(t+1)}=d^{(t)}p
\]

\end_inset


\end_layout

\begin_layout Standard
Given an initial distribution 
\begin_inset Formula $d^{(0)}$
\end_inset

 and the transition matrix 
\begin_inset Formula $p$
\end_inset

, the probabilities of all states the Markov chain can assume are defined
 for all time points 
\begin_inset Formula $t\geq0$
\end_inset

: 
\begin_inset Formula 
\[
d^{(t)}=d^{(0)}p^{t}
\]

\end_inset

.
\end_layout

\begin_layout Subparagraph
Stationary distribution
\end_layout

\begin_layout Standard
There are time-homogeneous Markov chains whose state distribution stays
 constant once it has assumed a certain state distribution.
 Such state distributions are called 
\emph on
invariant
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
invariant distribution
\end_layout

\end_inset


\emph on
 
\emph default
or 
\emph on
stationary distribution
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
stationary distribution
\end_layout

\end_inset

.
 A stationary distribution 
\begin_inset Formula $\pi$
\end_inset

 must fulfill the following equation: 
\begin_inset Formula 
\[
\pi p=\pi
\]

\end_inset

If 
\begin_inset Formula $d^{(t)}=\pi$
\end_inset

, then 
\begin_inset Formula $d^{(t+u)}=\pi$
\end_inset

 for all 
\begin_inset Formula $u\geq0$
\end_inset

.
 A Markov Chain can have more than one stationary distribution.
\end_layout

\begin_layout Subparagraph
Detailed balance/Reversibility
\end_layout

\begin_layout Standard
A Markov chain with transition matrix 
\begin_inset Formula $p$
\end_inset

 satisfies 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
detailed balance
\end_layout

\end_inset


\emph on
detailed balance 
\emph default
if there exists a probability distribution 
\begin_inset Formula $\pi=(\pi_{1},\pi_{2},\dots\pi_{n})$
\end_inset

 such that 
\begin_inset Formula 
\[
\pi_{j}p_{ji}=\pi_{i}p_{ij}
\]

\end_inset

.
 Such a Markov chain is also
\begin_inset Note Note
status open

\begin_layout Plain Layout
Is this true? In 
\begin_inset Quotes eld
\end_inset

neal.pdf
\begin_inset Quotes erd
\end_inset

, it says 
\begin_inset Quotes eld
\end_inset

Often, we will use time reversible homogeneous Markov chains that satisfy
 the 
\series bold
more restrictive 
\series default
condition of detailed balance
\begin_inset Quotes erd
\end_inset

.
 So Markov chains satisfying detailed balance seem to be a subset of the
 Markov chains satisfying time reversibility.
\end_layout

\end_inset

 called a 
\emph on
reversible
\emph default
 Markov chain
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
reversible Markov chain
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Norris1997"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Lemma 1.9.3
\end_layout

\end_inset

.
 A Markov chain with the detailed balance property is known to 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: why is detailed balance not enough for a Markov chain to have an unique
 stationary distribution in AltRBM-proof.pdf? why do we need irreducibility
 and aperiodicity?
\end_layout

\begin_layout Plain Layout
irreducibility has to be shown so that we can be sure that the markov chain
 has an unique stationary distribution.
\end_layout

\begin_layout Plain Layout
aperiodicity: 
\begin_inset Quotes eld
\end_inset

AltRBM-proof.pdf
\begin_inset Quotes erd
\end_inset

 says 
\begin_inset Quotes eld
\end_inset

One can show that an irreducible and aperiodic Markov chain on a finite
 state space is guarantied to converge to its stationary distribution (see,
 e.g., [6]).
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

have at least one stationary distribution, where the stationary distributions
 fulfill the 
\begin_inset Formula $\pi$
\end_inset

 from the detailed balance condition 
\begin_inset CommandInset citation
LatexCommand cite
key "Norris1997"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Lemma 1.9.2
\end_layout

\end_inset

.
 While having detailed balance implies that a Markov chain has a stationary
 distribution, the reverse is not true: there are Markov chains with a stationar
y distribution but not satisfying detailed balance.
 (For example, a Markov chain with transition probabilities 
\begin_inset Formula $p_{ij}=p_{jk}=p_{ki}=1$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset

, 
\begin_inset Formula $j\neq k$
\end_inset

, 
\begin_inset Formula $k\neq i$
\end_inset

, and the other entries of the transition matrix equal to 0 does not satisfy
 detailed balance, but 
\begin_inset Formula $\pi_{i}=\pi_{j}=\pi_{k}=\frac{1}{3}$
\end_inset

 is a stationary distribution of this Markov chain.)
\end_layout

\begin_layout Paragraph
Fundamental Theorem of Markov Chains
\begin_inset CommandInset label
LatexCommand label
name "par:Fundamental-Theorem-of-Markov-Chains"

\end_inset


\end_layout

\begin_layout Standard
Under what conditions does a Markov chain have an unique stationary distribution
? This is answered by the 
\emph on
Fundamental Theorem of Markov Chains
\emph default

\begin_inset Note Note
status open

\begin_layout Plain Layout
which was proved by Kolmogorov?.
 TODO
\end_layout

\end_inset

 (refer to e.g.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

).
 It states that, in the long run (i.e.
 
\begin_inset Formula $\lim_{t\rightarrow\infty}d^{(0)}p^{t}$
\end_inset

), the probability vector converges to the unique stationary distribution
 irrespective of the starting state 
\begin_inset Formula $d^{(0)}$
\end_inset

, given that 
\begin_inset Formula $p$
\end_inset

 is irreducible, positive-recurrent and aperiodic
\begin_inset Note Note
status open

\begin_layout Plain Layout
Theorem 7.4 in ~/uni/publication/zusammenfassung/markov chains/markovbuch2008.pdf.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Irgendwo an passender Stelle einfügen: 
\begin_inset Quotes eld
\end_inset

It is possible to efficiently calculate the stationary distribution 
\begin_inset Formula $\pi$
\end_inset

 by computing only the transition matrix for time steps that are a power
 of 2, i.e.
 
\begin_inset Formula $p^{2^{t}}$
\end_inset

.
 This can be done by repeated squaring and assignment: 
\begin_inset Formula $p^{2t}:=p^{t}p^{t}$
\end_inset

.
 (And starting with 
\begin_inset Formula $p^{1}:=p$
\end_inset

.)
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

.
 The definitions of irreducibility, positive recurrence, and aperiodicity
 follow.
\end_layout

\begin_layout Subparagraph
Irreducibility
\end_layout

\begin_layout Standard
A Markov Chain is called 
\emph on
irreducible
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
irreducible
\end_layout

\end_inset

, if it is possible to go from any state 
\begin_inset Formula $i$
\end_inset

 of the Markov Chain to any state 
\begin_inset Formula $j$
\end_inset

 (possibly in more than 1 steps).
 Formally, a Markov Chain is called irreducible, if its states are all in
 the same (and only) closed subset.
 A subset 
\begin_inset Formula $C$
\end_inset

 of 
\begin_inset Formula $\mathbb{S}$
\end_inset

 is called 
\emph on
closed 
\emph default
if 
\begin_inset Formula $p_{ij}=0$
\end_inset

 whenever 
\begin_inset Formula $i\in C$
\end_inset

 and 
\begin_inset Formula $j\notin C$
\end_inset

.
 (Remember that 
\begin_inset Formula $\mathbb{S}$
\end_inset

 is the set of possible states of the Markov Chain.)
\end_layout

\begin_layout Subparagraph
Positive Recurrence
\end_layout

\begin_layout Standard
A state 
\begin_inset Formula $i$
\end_inset

 of a Markov Chain is 
\emph on
positive recurrent
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
positive recurrent
\end_layout

\end_inset

, if we expect the Markov Chain to take an finite number of steps until
 it is in state 
\begin_inset Formula $i$
\end_inset

 again, when it started in state 
\begin_inset Formula $i$
\end_inset

 at time point 
\begin_inset Formula $0$
\end_inset

.
 To define positive recurrence formally, we have to define auxiliary measures
 first.
 The probability that state 
\begin_inset Formula $j$
\end_inset

 is visited for the first time -- at time step 
\begin_inset Formula $k$
\end_inset

 -- after the Markov Chain had been in state 
\begin_inset Formula $i$
\end_inset

 at time point 
\begin_inset Formula $0$
\end_inset

 is 
\begin_inset Formula 
\[
f_{ij}^{(k)}:=P(X_{1}\neq j,X_{2}\neq j,\dots,X_{k-1}\neq j,X_{k}=j|X_{0}=i)
\]

\end_inset

.
 The probability that state 
\begin_inset Formula $j$
\end_inset

 is ever reached from state 
\begin_inset Formula $i$
\end_inset

 is 
\begin_inset Formula 
\[
f_{ij}^{*}:=\sum_{k=1}^{\infty}f_{ij}^{(k)}
\]

\end_inset

.
 With this, we can define the expected number of steps for the Markov Chain
 to reach state 
\begin_inset Formula $j$
\end_inset

, when starting at state 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\[
\mu_{ij}:=\sum_{k=1}^{\infty}kf_{ij}^{(k)}
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
I won't use 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

 for positive recurrence, because he defines (on page 46 of markovbuch2008.pdf)
 
\begin_inset Formula $\mu_{ij}:=\sum_{k=1}^{\infty}kf_{ij}^{(k)}+(1-f_{ij}^{*})\infty$
\end_inset

, which is not defined for 
\begin_inset Formula $f_{ij}^{*}=1$
\end_inset

.
 I don't understand his definition.
\end_layout

\end_inset

.
 This number is also called the 
\emph on
mean recurrence time
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
mean recurrence time
\end_layout

\end_inset

.
 With these definitions, we can define a state to be 
\emph on
transient
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
transient
\end_layout

\end_inset

, positive recurrent, or 
\emph on
null recurrent
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
null recurrent
\end_layout

\end_inset

:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}<1$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called transient.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called recurrent.
\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

 and 
\begin_inset Formula $\mu_{ii}<\infty$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
positive recurrent
\emph default
.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

 and 
\begin_inset Formula $\mu_{ii}=\infty$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
null recurrent
\emph default
.
\end_layout

\end_deeper
\begin_layout Standard
It can be proven that when there are finitely many states, there are no
 null recurrent states (see Proposition 7.2.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

).
\end_layout

\begin_layout Subparagraph
Aperiodicity
\end_layout

\begin_layout Standard
The definition of an 
\emph on
aperiodic
\emph default
 state is shorter.
 The period of a state
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
period of a state
\end_layout

\end_inset

 
\begin_inset Formula $i$
\end_inset

 is defined as the greatest common denominator of the number of time steps
 needed for a Markov chain so that it is possible to be in state 
\begin_inset Formula $i$
\end_inset

 again, after it was in state 
\begin_inset Formula $i$
\end_inset

 before: 
\begin_inset Formula 
\[
period(i)=gcd(\{k|k\geq0,p_{ii}^{k}>0\})
\]

\end_inset

.
 If 
\begin_inset Formula $period(i)=1$
\end_inset

, state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
aperiodic
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
aperiodic
\end_layout

\end_inset

.
 If all states of a Markov chain are aperiodic, the Markov chain is called
 aperiodic.
\end_layout

\begin_layout Subparagraph
Markov Chain Monte Carlo (MCMC)
\end_layout

\begin_layout Standard

\emph on
Markov Chain Monte Carlo
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
Markov Chain Monte Carlo algorithm
\end_layout

\end_inset

 is a type of algorithm to sample from a multivariate probability distribution.
 A Markov Chain has to be set up so that it 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: And also write down how the target distribution is specified.
 At this point I think that this depends on the specific instance of MCMC,
 e.g.
 Gibbs Sampling needs conditional probabilities.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Gibbs Sampling
\end_layout

\begin_layout Standard
Here, we will introduce Gibbs Sampling to show how 
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 used it to approximate inference in directed and undirected graphical models.
\end_layout

\begin_layout Standard

\emph on
Gibbs Sampling
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Gibbs Sampling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "GemanGeman1984"

\end_inset


\emph on
 
\emph default
is an instance of a Markov Chain Monte Carlo (MCMC) algorithm.
 Its goal is to generate samples from a multivariate joint probability distribut
ion, without having to know its closed form.
 The generated samples can then be used to compute an approximation of the
 mean of a distribution, for example.
\end_layout

\begin_layout Standard
To use a Gibbs Sampler, one must construct a Markov chain with its (only)
 stationary distribution equal to the target distribution.
 Because its goal is to sample from a multivariate probability distribution,
 each of the random variables are updated in turn, based on the conditional
 probabilities.
\end_layout

\begin_layout Subparagraph
Gibbs Sampling Requires Closed-form Conditional Probabilities
\end_layout

\begin_layout Standard
This means that a precondition to being able to use a Gibbs Sampler is that
 the following conditional probabilities of the target distribution are
 known, so that they can be evaluated.
 Suppose that the multivariate target distribution is 
\begin_inset Formula $P(X_{1},\dots,X_{n})$
\end_inset

.
 Then for each random variable 
\begin_inset Formula $X_{i}\in\{X_{1},\dots,X_{n}\}$
\end_inset

 the conditional probability of the variable given all other variables must
 be known in closed form: 
\begin_inset Formula 
\[
P(X_{i}|\mathbf{X_{j}},j\in\{1,\dots,n\}\backslash i)=P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},X_{n})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: das hier evtl.
 weglassen: es reicht nicht nur dass man faster samplen kann aus der conditional
, sondern man muss ja auch iterieren.
 
\begin_inset Quotes eld
\end_inset

It should also be faster to sample from these conditional probability distributi
ons than from the joint target probability distribution (should it be known),
 because otherwise one should just sample from the joint distribution directly,
 and not use Gibbs sampling.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: hier schreiben, dass die Markov-Kette aus dem Produkt der einzelnen
 Variable-Updates (
\begin_inset Quotes eld
\end_inset

base transitions
\begin_inset Quotes erd
\end_inset

) gebildet wird.
 Siehe Neal93, Kapitel 4.1 (Seite 47).
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Neal schreibt auf Seite 44 ganz unten: 
\begin_inset Quotes eld
\end_inset

For example, each 
\begin_inset Formula $B_{k}$
\end_inset

 might change only some subset of the variables making up the state.
\begin_inset Quotes erd
\end_inset

 Also definiert er anscheinend Markov-Ketten mit mehrdimensionalem state
 vector?
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Gibbs Sampling using a Markov Chain
\end_layout

\begin_layout Standard
The variable updates in Gibbs sampling can be regarded as a Markov chain.
 However, we must first define how the random variables of Gibbs sampling
 are mapped to the random variable of the Markov chain.
 One theoretic possibility is to re-map the random variables and their states
 to a single random variable.
\end_layout

\begin_layout Standard
Above, Markov chains were defined for a single state variable 
\begin_inset Formula $X$
\end_inset

.
 But in Gibbs sampling there are usually more than one variable, written
 
\begin_inset Formula $X_{i}\in\{X_{1},\dots,X_{n}\}$
\end_inset

 above.
 If there are a finite number of random variables in Gibbs sampling, i.e.,
 if 
\begin_inset Formula $n$
\end_inset

 is finite, and the state space of these variables is also finite, say of
 size 
\begin_inset Formula $m$
\end_inset

, then the (therefore also finite) number of states of these variables can
 be encoded in a single variable with a state space of size 
\begin_inset Formula $m^{n}$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
e.g.
 let's say there are 3 variables, each of which can assume 2 states.
 and i want to encode these 
\begin_inset Formula $2^{3}$
\end_inset

 different possible states in 1 variable.
 then I have 1 variable with 
\begin_inset Formula $2*2*2$
\end_inset

 different possible states.
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Constructing a Markov Chain from Base Transitions
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 suggests
\begin_inset Note Note
status open

\begin_layout Plain Layout
on page 45
\end_layout

\end_inset

 constructing a time-homogeneous Markov Chain from a weighted mixture of
 base transitions, each of which describe the probability of a state change
 of one random variable.
 The base transitions are named 
\begin_inset Formula $B_{k}(x,x')$
\end_inset

, where 
\begin_inset Formula $k$
\end_inset

 is the number of the base transition, 
\begin_inset Formula $x$
\end_inset

 is the starting state of the transition, 
\begin_inset Formula $x'$
\end_inset

 is the target state of the transition, and the whole term 
\begin_inset Formula $B_{k}(x,x')$
\end_inset

 is the probability of the transition, which must be strictly greater than
 zero for all values of 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $x'$
\end_inset

, to make the Markov chain irreducible.
 A weighted mixture can then be constructed as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T(\mathbf{x},\mathbf{x}')=\sum_{k}\alpha_{k}B_{k}(x,x')
\]

\end_inset

 where 
\begin_inset Formula $\alpha_{k}$
\end_inset

 is the weight of base transition 
\begin_inset Formula $B_{k}$
\end_inset

, and the weights must fulfill 
\begin_inset Formula $\alpha_{k}>0$
\end_inset

 and 
\begin_inset Formula $\sum_{k}\alpha_{k}=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 also notes that the required properties for a Markov chain to converge
 are fulfilled: If each of the base transitions 
\begin_inset Formula $B_{k}$
\end_inset

 have the same stationary distribution, then the mixture 
\begin_inset Formula $T$
\end_inset

 also has this stationary distribution.
 In addition, if each of the base transitions satisfy detailed balance,
 then the mixture also does.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Hier fehlt wie die Markov Chain genau aussehen muss.
 Wie werden die random variables des Gibbs sampling auf die eine random
 variable der Markov chain gemappt? Wie wird sichergestellt, dass die Markov
 Chain konvergiert?
\end_layout

\begin_layout Plain Layout
Hier muss stehen, dass die Markov Chain nur dann konvergiert, wenn alle
 probabilities strictly positive sind (i.e.
 nicht 0).
 (Siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

, Seite 48: 
\begin_inset Quotes eld
\end_inset

...
 provided that all the conditional probabilities used to define the B k
 in equation (4.1) are non-zero.
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Plain Layout
Ich glaube in 
\begin_inset CommandInset citation
LatexCommand cite
key "FischerIgel2012"

\end_inset

 steht das auch.)
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Initialization of the Gibbs Sampler
\end_layout

\begin_layout Standard
A Gibbs Sampler starts by specifying a start value 
\begin_inset Formula $x_{i}^{(0)}$
\end_inset

 for each random variable 
\begin_inset Formula $X_{i}$
\end_inset

.
 Since the Markov chain must be constructed such that it converges to its
 only stationary distribution the choice of start values is not critical,
 but it influences the numbers of iterations needed until the Gibbs Sampler
 returns samples from the target distribution.
 So the start value should be close to the 
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

 of the distribution.
\end_layout

\begin_layout Subparagraph
Iterations
\end_layout

\begin_layout Standard
Then an iterative process is started.
 In each iteration 
\begin_inset Formula $t$
\end_inset

, each random variable 
\begin_inset Formula $X_{i}$
\end_inset

 is updated by sampling a new value 
\begin_inset Formula $x_{i}^{(t)}$
\end_inset

 from the conditional probability distribution 
\begin_inset Formula 
\begin{equation}
P(X_{i}|X_{1}=x_{1}^{(t-1)},\dots,X_{i-1}=x_{i-1}^{(t-1)},X_{i+1}=x_{i+1}^{(t-1)},\dots,X_{n}=x_{n}^{(t-1)})\label{eq:Gibbs sampling: CPD}
\end{equation}

\end_inset

.
 Then all the other variables must be updated.
\end_layout

\begin_layout Standard
There are different alternative ways in which the random variables are updated,
 for example updating the random variables can be done in random order,
 or sequentially, or a whole 
\begin_inset Quotes eld
\end_inset

block
\begin_inset Quotes erd
\end_inset

 of multiple random variables can be sampled from the conditional distribution
 given all the other random variables (e.g.
 
\begin_inset Formula $P(X_{i_{1}},X_{i_{2}},X_{i_{3}}|\mathbf{X_{j}=x_{j}^{(t-1)}},j\in\{1,\dots,n\}\backslash\{i_{1},i_{2},i_{3}\})$
\end_inset

).
\end_layout

\begin_layout Standard
If the Markov chain fulfills irreducibility, positive recurrence, and aperiodici
ty, then it is guaranteed to converge to its stationary distribution (see
 
\begin_inset CommandInset ref
LatexCommand vref
reference "par:Fundamental-Theorem-of-Markov-Chains"

\end_inset

).
 However there is currently no known method to determine when the Markov
 chain has done so, which leads to the following two practices, 
\emph on
burn-in
\emph default
 and 
\emph on
thinning
\emph default
.
\end_layout

\begin_layout Subparagraph
Burn-in Period
\end_layout

\begin_layout Standard
The starting value of the random variable might be far from the 
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

 of the distribution.
 But after some number of throw-away iterations, the Gibbs Sampler's values
 
\begin_inset Formula $\mathbf{x}=(x_{1},\dots,x_{n})$
\end_inset

 will start coming from the target joint distribution 
\begin_inset Formula $P(X_{1},\dots,X_{n})$
\end_inset

.
 This 
\begin_inset Quotes eld
\end_inset

some number of throw-away iterations
\begin_inset Quotes erd
\end_inset

 is called the 
\emph on
burn-in period
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
burn-in period
\end_layout

\end_inset

 and can be considerable depending on the starting values and the joint
 probability distribution underlying the conditional probability distributions.
 If one knows where the 
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

 of the equilibrium distribution is then one should use a value near that
 center as the starting point, however, in many cases such things are not
 known (and are the goal of Gibbs sampling in the first place).
\end_layout

\begin_layout Standard
There is no known analytic method to determine when a chain is burned-in.
 Several convergence diagnostics methods have been proposed, see e.g.
 
\begin_inset CommandInset citation
LatexCommand cite
key "CowlesCarlin1996"

\end_inset

 for a review.
\end_layout

\begin_layout Subparagraph
Thinning
\end_layout

\begin_layout Standard
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
thinning
\end_layout

\end_inset

Even after the Markov chain is burned in, there is still a problem with
 the returned samples, which prevent them from being used in those applications
 needing 
\emph on
independent 
\emph default
samples.
 The samples of two adjacent time steps 
\begin_inset Formula $\mathbf{x}^{(t)}$
\end_inset

 and 
\begin_inset Formula $\mathbf{x}^{(t+1)}$
\end_inset

 are correlated however because the latter is dependent on the former (by
 definition).
\end_layout

\begin_layout Standard
This can be mitigated by returning only the states of every 
\emph on

\begin_inset Formula $n$
\end_inset


\emph default
th iteration, where 
\begin_inset Formula $n$
\end_inset

 is a sufficiently large number.
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: is this true?
\end_layout

\end_inset

 This is called 
\begin_inset Quotes eld
\end_inset

thinning
\begin_inset Quotes erd
\end_inset

 of the Gibbs sampler.
\end_layout

\begin_layout Standard
Again, also here there is currently no straightforward analytic way to determine
 what a sufficiently large 
\begin_inset Formula $n$
\end_inset

 is for the adjacent 
\begin_inset Formula $\mathbf{x}$
\end_inset

 to be regarded independent.
 In practice on resorts to heuristics like autocorrelation.
\end_layout

\begin_layout Subsubsection
Inference in Markov Random Fields
\begin_inset CommandInset label
LatexCommand label
name "sub:Inference-in-Markov-Random-Fields"

\end_inset


\end_layout

\begin_layout Paragraph
Gibbs Sampling in Markov Random Fields
\begin_inset CommandInset label
LatexCommand label
name "par:Gibbs-Sampling-in-Markov-Random-Fields"

\end_inset


\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset ref
LatexCommand vref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

 we described how exact inference in Markov Random Fields can be done by
 conditioning on the known random variables and marginalizing out the uninterest
ing variables.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

 stated that the exponential runtime of exact inference can be circumvented
 by approximate methods like Gibbs sampling.
 Here we address that claim.
\end_layout

\begin_layout Standard
The random variables of the Markov Random Field will be named like those
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

.
 The interesting variables are named 
\begin_inset Formula $\mathbf{W}$
\end_inset

, the variables whose states are known (for example because they were measured)
 
\begin_inset Formula $\mathbf{K}$
\end_inset

, and the variables we are not interested in 
\begin_inset Formula $\mathbf{U}$
\end_inset

.
 The union of all random variables is called 
\begin_inset Formula $\mathbf{X}:=\mathbf{U}\cup\mathbf{K}\cup\mathbf{W}$
\end_inset

.
\end_layout

\begin_layout Standard
Gibbs Sampling in Markov Random Fields uses a converging Markov chain to
 sample from the target joint probability distribution.
\end_layout

\begin_layout Enumerate
A prerequisite is that the conditional probability distributions are known
 in closed form.
\end_layout

\begin_layout Enumerate
Initialize the state 
\begin_inset Formula $x_{i}^{(1)}$
\end_inset

 of the random variable 
\begin_inset Formula $X_{i}\in\mathbf{W}\cup\mathbf{U}$
\end_inset

 with an arbitrary value.
\end_layout

\begin_layout Enumerate
Initialize the state 
\begin_inset Formula $x_{i}^{(1)}$
\end_inset

 of the known random variables 
\begin_inset Formula $X_{i}\in\mathbf{K}$
\end_inset

 with their known state.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset label
LatexCommand label
name "enu:For-each-time"

\end_inset

For each time point 
\begin_inset Formula $t\in\{2,3,\dots\}$
\end_inset

 do
\end_layout

\begin_deeper
\begin_layout Enumerate
Keep the known variables fixed (i.e.
 
\begin_inset Formula $x_{i}^{(t+1)}:=x_{i}^{(t)}$
\end_inset

 for all 
\begin_inset Formula $X_{i}\in\mathbf{K}$
\end_inset

).
\end_layout

\begin_layout Enumerate
For each random variable 
\begin_inset Formula $X_{i}\in\mathbf{W}\cup\mathbf{U}$
\end_inset

 do
\end_layout

\begin_deeper
\begin_layout Enumerate
Given the states of all variables 
\begin_inset Formula $\mathbf{X}\backslash X_{i}$
\end_inset

, sample a new 
\begin_inset Formula $X_{i}$
\end_inset

 from its conditional distribution 
\begin_inset Formula $P(X_{i}=x_{i}^{(t+1)}|X_{1}=x_{1}^{(t)},\dots,X_{i-1}=x_{i-1}^{(t)},X_{i+1}=x_{i+1}^{(t)},\dots,X_{n}=x_{n}^{(t)})$
\end_inset

.
 Due to the Hammersley-Clifford theorem
\begin_inset CommandInset ref
LatexCommand eqref
reference "par:Hammersley-Clifford-theorem"

\end_inset

 this conditional probability is equal to 
\begin_inset Formula $P(X_{i}=x_{i}^{(t+1)}|\mathbf{X}_{Neighborhood(X_{i})})$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Repeat (
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:For-each-time"

\end_inset

) until the Markov chain converges.
\end_layout

\begin_layout Enumerate
Discard the states of the uninteresting random variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Return the states of the interesting random variables 
\begin_inset Formula $\mathbf{W}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Gibbs Sampling in Bayesian Networks
\end_layout

\begin_layout Standard
The conditional probability of 
\begin_inset Formula $X_{i}$
\end_inset

 given all other nodes is equal to its conditional probability given the
 values of the nodes in 
\begin_inset Formula $X_{i}$
\end_inset

's Markov Blanket 
\begin_inset Formula $X_{MarkovBlanket(X_{i})}$
\end_inset


\begin_inset Formula 
\[
P(X_{i}=x_{i}\mid\mathbf{X_{j}}=\mathbf{x_{j}}:j\neq i)=P(X_{i}=x_{i}\mid\mathbf{X}_{MarkovBlanket(X_{i})}=\mathbf{x}_{MarkovBlanket(X_{i})})
\]

\end_inset

.
 This conditional probability is needed for Gibbs Sampling from a Bayesian
 Network: We use the same algorithmic structure as for Markov Random Fields
 above (
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Gibbs-Sampling-in-Markov-Random-Fields"

\end_inset

), but sample from 
\begin_inset Formula $P(X_{i}=x_{i}\mid\mathbf{X}_{MarkovBlanket(X_{i})}=\mathbf{x}_{MarkovBlanket(X_{i})})$
\end_inset

 when updating the state of 
\begin_inset Formula $X_{i}$
\end_inset

 in step 4(b).
\end_layout

\begin_layout Standard
\begin_inset Formula $P(X_{i}=x_{i}\mid X_{MarkovBlanket(X_{i})})$
\end_inset

 is equal to:
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rewrite the algorithm from 
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

: 
\begin_inset Quotes eld
\end_inset

We start the Gibbs sampling procedure by fixing the observed variables to
 their known values, and setting the unobserved variables arbitrarily.
 We then repeatedly visit each unobserved variable in turn, each time randomly
 selecting a new value for the variable from its conditional distribution
 given the current values of the other variables.
 From the joint distribution of equation (2.15), we see that the conditional
 distribution for X k is as follows:
\begin_inset Quotes erd
\end_inset

 Diese Formel hier einfügen.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Comparison of Gibbs Sampling in Markov Random Fields and Bayesian Networks
\end_layout

\begin_layout Standard
Gibbs Sampling in Markov Random Fields is easier than Gibbs Sampling in
 directed graphical models.
 This is because the conditional probability distributions needed for Gibbs
 Sampling are simpler than those in Bayesian Networks.
 The conditional probability distribution needed in Gibbs Sampling was given
 in equation 
\begin_inset CommandInset ref
LatexCommand vref
reference "eq:Gibbs sampling: CPD"

\end_inset

.
 This conditional probability is particularly simple for Markov Random Fields,
 because of the local Markov property (refer to 
\begin_inset CommandInset ref
LatexCommand vref
reference "local-Markov-property"

\end_inset

): each random variable 
\begin_inset Formula $X_{i}$
\end_inset

 is independent of all other random variables given the states of the neighborin
g random variables.
 This means that in Markov Random Fields, equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Gibbs sampling: CPD"

\end_inset

 is 
\begin_inset Formula 
\[
P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},\dots,X_{n})=P(X_{i}|\mathbf{X}_{Neighborhood(X_{i})})
\]

\end_inset

.
 For comparison, in Bayesian Networks the conditional probability would
 be 
\begin_inset Formula 
\[
P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},\dots,X_{n})=P(X_{i}|\mathbf{X}_{MarkovBlanket(X_{i})})
\]

\end_inset

, where 
\begin_inset Formula $\mathbf{X}_{MarkovBlanket(X_{i})}$
\end_inset

 are the random variables in the Markov Blanket of 
\begin_inset Formula $X_{i}$
\end_inset

.
 The Markov Blanket of a random variable is more complicated to compute
 than its neighborhood.
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: define Markov Blanket.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Explaining away
\end_layout

\begin_layout Standard
Directed graphical models show the phenomenon of 
\begin_inset Quotes eld
\end_inset

explaining away
\begin_inset Quotes erd
\end_inset

, which complicates inference.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: is there also explaining away in undirected graphs? nope, I don't
 think so.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Boltzmann Machines
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: probably move this to its own (sub)section
\end_layout

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: in the following, replace the word 
\begin_inset Quotes eld
\end_inset

unit
\begin_inset Quotes erd
\end_inset

 with 
\begin_inset Quotes eld
\end_inset

node
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Elaborate the definition
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A Boltzmann Machine is an undirected graphical model that has a specific
 form of the conditional probability distribution defined at each node.
\end_layout

\begin_layout Subparagraph
Gibbs Sampling in Boltzmann Machines
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: probably move this somewhere else
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Since a Boltzmann Machine is an undirected graphical model, the inference
 algorithm from 
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 applies.
 See 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Inference-in-Markov-Random-Fields"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rewrite the following using consistent variable names and fonts.
\end_layout

\begin_layout Plain Layout
TODO: the following is only for binary nodes, i.e.
 they can only have either state 0 or state 1.
 Do I find a generalization to (discrete multiple states) / (continuous)
 nodes somewhere?
\end_layout

\begin_layout Plain Layout
Neal
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 writes (on page 75) how to approximate the probability distribution of
 a specific variable 
\begin_inset Formula $S_{i}$
\end_inset

, given the states of all other variables 
\begin_inset Formula $S_{j}$
\end_inset

, 
\begin_inset Formula $i\neq j$
\end_inset

 in a Boltzmann machine:
\begin_inset Formula 
\[
P(S_{i}=x|S_{j})=\sigma((2x-1)\sum_{j\neq i}s_{j}w_{ij})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Note Note
status open

\begin_layout Plain Layout
(this formula is only valid for 0/1-valued nodes.)
\end_layout

\end_inset

 This conditional probability is needed for Gibbs sampling.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: define 
\begin_inset Formula $\sigma(x)=\frac{1}{1+\exp(-x)}$
\end_inset

 somewhere
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Training Boltzmann Machines
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: probably move this somewhere else
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rewrite the following using consistent variable names and fonts.
\end_layout

\begin_layout Plain Layout
Neal writes (on page 75) about training of Boltzmann machines, i.e.
 adjusting the weights so that a set of training samples 
\begin_inset Formula $T$
\end_inset

 (i.e.
 measured states of the visible units) become as probable as possible.
 The log-likelihood is 
\begin_inset Formula $L=\log\prod_{v\in T}P(V=v)$
\end_inset

.
 The derivative of the log-likelihood with respect to a weight is: 
\begin_inset Formula $\frac{\partial L}{\partial w_{ij}}=\beta\sum_{\mathbf{v}\in\mathbf{T}}(\sum_{s}P(\mathbf{S=s}|\mathbf{V=v})s_{i}s_{j}-\sum_{\mathbf{s}}P(\mathbf{S=s})s_{i}s_{j})$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: derive 
\begin_inset Formula $\frac{\partial L}{\partial w_{ij}}$
\end_inset


\end_layout

\end_inset

 (
\begin_inset Formula $\beta$
\end_inset

 is defined on page 74 to be 1 for 0/1-valued nodes, and 
\begin_inset Formula $\frac{1}{2}$
\end_inset

 for -1/1-valued nodes.)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This derivative can be approximated by two parallel Gibbs sampling steps:
 the 
\begin_inset Quotes eld
\end_inset

positive
\begin_inset Quotes erd
\end_inset

 phase, where 
\begin_inset Formula $P(\mathbf{S=s}|\mathbf{V=v})$
\end_inset

 is approximated, and the 
\begin_inset Quotes eld
\end_inset

negative
\begin_inset Quotes erd
\end_inset

 phase, where 
\begin_inset Formula $P(\mathbf{S=s})$
\end_inset

 is approximated.
\end_layout

\begin_layout Subparagraph
Positive Phase
\end_layout

\begin_layout Standard
In more detail, in the positive phase
\begin_inset Index idx
status open

\begin_layout Plain Layout
positive phase
\end_layout

\end_inset

, the visible nodes 
\begin_inset Formula $\mathbf{V}$
\end_inset

 are clamped (i.e.
 their state is held fixed) to their states as they are in the training
 sample 
\begin_inset Formula $\mathbf{v}$
\end_inset

, and then the states of the remaining (i.e.
 hidden) nodes are sampled via Gibbs sampling.
 This means starting in any (for example random, or close to equilibrium)
 configuration of the remaining nodes, repeatedly sampling each remaining
 variable 
\begin_inset Formula $S_{i}$
\end_inset

 from its conditional probability distribution given the states of all other
 variables (i.e.
 
\begin_inset Formula $P(S_{i}|S_{j:j\neq i}=s_{j})$
\end_inset

) until the Gibbs sampler reaches equilibrium, and recording the state 
\begin_inset Formula $s_{i}$
\end_inset

 that each remaining variable 
\begin_inset Formula $S_{i}$
\end_inset

 had assumed in equilibrium.
 By repeatedly sampling the 
\begin_inset Formula $s_{i}$
\end_inset

 a few times when the Markov chain is in equilibrium, we determine their
 probability distributions.
 This means the conditional probability distribution of the remaining variables
 
\begin_inset Formula $P(\mathbf{S=s}|\mathbf{V=v})$
\end_inset

 is determined, and therefore the term 
\begin_inset Formula $\sum_{s}P(\mathbf{S=s}|\mathbf{V=v})s_{i}s_{j}$
\end_inset

 can be determined, which completes the positive phase.
\end_layout

\begin_layout Subparagraph
Negative Phase
\end_layout

\begin_layout Standard
In the negative phase
\begin_inset Index idx
status open

\begin_layout Plain Layout
negative phase
\end_layout

\end_inset

 no nodes are clamped, and the states of all variables in equilibrium are
 recorded.
 Again, we start in any configuration of the network.
 Then we repeatedly sample from the conditional probability distributions
 
\begin_inset Formula $P(S_{i}|S_{j:j\neq i}=s_{j})$
\end_inset

 for all variables 
\begin_inset Formula $S_{i}$
\end_inset

 until equilibrium, and record the state 
\begin_inset Formula $s_{i}$
\end_inset

 each variable 
\begin_inset Formula $S_{i}$
\end_inset

 had in equilibrium.
 Sampling a few more steps in equilibrium, we can determine their distributions
 
\begin_inset Formula $P(\mathbf{S=s})$
\end_inset

 and therefore the term 
\begin_inset Formula $\sum_{\mathbf{s}}P(\mathbf{S=s})s_{i}s_{j}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Belief Network
\end_layout

\begin_layout Standard
Belief networks can be seen as the stochastic counterpart of deterministic
 feed-forward networks.
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I should make a small section on feed-forward networks, like the one
 on Hopfield networks (but maybe shorter).
 A definition of feed-forward networks is also needed later for mentioning
 that a learned Deep Belief Networks can be interpreted as a feed-forward
 network.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A belief network is a directed graphical model.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
A sigmoid belief network is a belief network in which the conditional probabilit
y associated with node 
\begin_inset Formula $N_{i}$
\end_inset

 can be expressed as 
\begin_inset Formula $P(N_{i}=n_{i}|\mathbf{N_{j}=n_{j}}:\mathbf{j}<i)=\sigma((2n_{i}-1)\sum_{j<i}n_{j}w_{ij})$
\end_inset

.
\end_layout

\begin_layout Plain Layout
TODO: Do I need _sigmoid_ belief networks at all? In the 
\begin_inset Quotes eld
\end_inset

A Fast Learning Algorithm for Deep Belief Nets
\begin_inset Quotes erd
\end_inset

 paper by Hinton, Osindero, and Teh the word 
\begin_inset Quotes eld
\end_inset

sigmoid
\begin_inset Quotes erd
\end_inset

 does not appear at all.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
According to 
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/rbm/reweighted weight-sleep.pdf
\begin_inset Quotes erd
\end_inset

, a Sigmoidal Belief Network (SBN) is a directed graphical model with independen
t variables 
\begin_inset Formula $x_{i}$
\end_inset

 given the parents 
\begin_inset Formula $\mathbf{y}$
\end_inset

:
\begin_inset Formula 
\[
P^{SBN}(x_{i}=1|\mathbf{y})=\sigma(W^{i,:}\mathbf{y}+b_{i})
\]

\end_inset

And they say that although a SBN is a very simple generative model given
 
\begin_inset Formula $\mathbf{y}$
\end_inset

, inference for 
\begin_inset Formula $\mathbf{y}$
\end_inset

 given x is in general intractable.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
More formally, the random variables 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Wie man die 
\begin_inset Formula $P(\tilde{S}=\tilde{s}|\tilde{V}=\tilde{v})$
\end_inset

 mittels Gibbs-Sampling bestimmt, beschreibt Neal auf Seite 80: 
\begin_inset Quotes eld
\end_inset

To exhibit these marginal and conditional distributions via Gibbs sam- pling,
 we must repeatedly select a new value for each unit from its distri- bution
 conditional on the rest of the network.
 This distribution is given by the proportionality 
\begin_inset Formula 
\begin{eqnarray*}
P(S_{i}=x|S_{j}=s_{j}:j\neq i) & = & P(S_{i}=x|S_{j}=s_{j}:j<i)\\
 &  & *\prod_{j>i}P(S_{j}=s_{j}|S_{i}=x,S_{k}=s_{k}:k<j,k\neq i)
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Plain Layout
In the case of a sigmoid activation function, this equation is:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{eqnarray*}
P(S_{i}=x|S_{j}=s_{j}:j\neq i) & = & \sigma(x^{*}\sum_{j<i}s_{j}w_{ij})\\
 &  & *\prod_{j>i}\sigma(s_{j}^{*}(xw_{ji}+\sum_{k<j,k\neq i}s_{k}w_{jk}))
\end{eqnarray*}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Die Equation hier ist ein Mix aus Eq.
 (9) und (17)
\end_layout

\end_inset

.
\end_layout

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

To select a new value from the above distribution, unit i must have available
 both its own total input: 
\begin_inset Formula $\sum_{j<i}s_{j}w_{ij}$
\end_inset

 and the input to each unit, j, that it feeds into, exclusive of its own
 contribution: 
\begin_inset Formula $\sum_{k<j,k\neq i}s_{k}w_{jk}$
\end_inset

.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Plain Layout
(Der 
\begin_inset Formula $*$
\end_inset

 auf manchen 
\begin_inset Formula $s$
\end_inset

 oder 
\begin_inset Formula $x$
\end_inset

, z.B.
 
\begin_inset Formula $x^{*}$
\end_inset

 oder 
\begin_inset Formula $s_{j}^{*}$
\end_inset

 bezieht sich auf Knoten, in denen -1/1 Zustände verwendet anstatt 0/1:
 Seite 80: 
\begin_inset Quotes eld
\end_inset

for -1/+1-valued units, 
\begin_inset Formula $s_{i}^{*}=s_{i}$
\end_inset

, while for 0/1-valued units, 
\begin_inset Formula $s_{i}^{*}=2s_{i}-1$
\end_inset

.
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Neal writes about the training of weights to maximize the likelihood given
 the observed training cases in Sigmoid Belief Networks in 
\begin_inset Quotes eld
\end_inset

Connectionist learning of belief networks
\begin_inset Quotes erd
\end_inset

 (
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/rbm/A11 Connectionist learning of belief
 networks.pdf
\begin_inset Quotes erd
\end_inset

) on (the paper's printed page numbers) pages 82/83:
\end_layout

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

Next, we must find values for the network weights that maximize the likelihood
 given the training cases, though to avoid overfitting or to reduce computation
 we might decide to fix certain weights at zero based on a priori knowledge.
 Other weights will be set to zero (or to small random values if we wish
 to break symmetry faster) and then adjusted by gradient-ascent so as to
 maximize the log-likelihood: [...] These partial derivatives can be evaluated
 by running a separate Gibbs sampling simulation of the network for each
 training case, clamping the visi- ble units to the values they take in
 that training case and observing the state vectors that arise as a result.
 [...] Incrementing each weight, Wij, by a small amount proportional to the
 average value of [...] over the combined samples for all training cases will
 then move the weights along the gradient toward a local maximum of the
 likelihood.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Plain Layout
Man kann also trainieren, indem man 
\begin_inset Formula $P(\tilde{S}=\tilde{s}|\tilde{V}=\tilde{v})$
\end_inset

 mittels Gibbs-Sampling bestimmt, dann mit 
\begin_inset Formula $s_{i}s_{j}\sigma(-s_{i}\sum_{k<i}s_{k}w_{ik})$
\end_inset

 multipliziert, und das Ergebnis (mal einer learning rate) dann auf die
 Weight 
\begin_inset Formula $w_{ij}$
\end_inset

 addiert.
\end_layout

\begin_layout Plain Layout
--------------------
\end_layout

\begin_layout Plain Layout
Neal schreibt auf Seite 86 (bzw.
 proof auf Seite 109, dass für bis zu 2 Knoten alle möglichen joint probability
 distributions mit Boltzmann machine als auch mit sigmoid belief network
 modellierbar sind.
 Bei 3 Knoten sind nicht mehr alle joint probability distributions modellierbar,
 aber die, die von einer Bolzmann machine modellierbar sind, sind auch von
 einem sigmoiden Belief Network modellierbar und umgekehrt.
 Ab 4 oder mehr Knoten sind die joint probability distributions, die von
 einer Boltzmann machine und von einem sigmoid belief network modellierbar
 sind, unterschiedlich.
\end_layout

\begin_layout Plain Layout
Allerdings schreibt Neal auf Seite 72: 
\begin_inset Quotes eld
\end_inset

With the help of "hidden" units, all these networks [Boltzmann machine und
 sigmoid belief network] can represent arbitrary distributions over a set
 of "visible" units.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Both Boltzmann machines and sigmoid belief networks can represent arbitrary
 probability distributions over a set of an arbitrary number of visible
 units, provided that a sufficient number of hidden units is available.
\end_layout

\begin_layout Subparagraph
Deep Belief Network
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: irgendwo vor Deep Belief Networks muss ich einen Abschnitt machen,
 wo ich erkläre dass viele der Netzwerk-Lernmethoden gradient descent machen.
 Deep Belief Networks machen das auch, aber keine maximum likelihood estimation,
 sondern eine contrastive divergence.
 Siehe section 3 in 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Irgendwo vor Deep Belief Networks muss ich contrastive divergence
 erklären.
 Das Folgende kommt aus 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

, Seite 1534.
\end_layout

\begin_layout Plain Layout
Maximum likelihood learning minimizes the Kullback-Leibler divergence 
\begin_inset Formula $KL(P^{0}||P_{\theta}^{\infty})$
\end_inset

 where 
\begin_inset Formula $P^{0}$
\end_inset

 is the distribution of the data, and 
\begin_inset Formula $P_{\theta}^{\infty}$
\end_inset

 is the equilibrium distribution of the model, when running the Gibbs chain
 until equilibrium.
\end_layout

\begin_layout Plain Layout
Contrastive divergence learning (
\begin_inset Note Note
status open

\begin_layout Plain Layout
cite: Hinton, G.
 E.
 (2002).
 Training products of experts by minimizing contrastive diver- gence, Neural
 Computation, 14(8), 1711–1800.
\end_layout

\end_inset

) runs the Gibbs chain for only 
\begin_inset Formula $n$
\end_inset

 steps.
 Contrastive divergence learning minimizes the difference of two Kullback-Leible
r divergences 
\begin_inset Formula $KL(P^{0}||P_{\theta}^{\infty})-KL(P_{\theta}^{n}||P_{\theta}^{\infty})$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

 introduced the 
\emph on
deep belief network 
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
deep belief network
\end_layout

\end_inset

.
 It is a directed graphical model, composed of multiple layers consisting
 of one or several nodes.
 Imagine the layers arranged and numbered from top to bottom.
 The nodes in the top two layers are connected using undirected connections.
 The nodes in the second layer and the layers below have directed (outgoing)
 connections only to nodes in the adjacent layer below.
\end_layout

\begin_layout Standard
This is a network in which nodes in the bottom layer correspond to the (observed
) random variables in the training set and the nodes in the layer above
 are the (hidden) causes of the visible nodes, which can in turn have other
 hidden causes.
 As originally defined, each random variable is binary.
 The probability that a node 
\begin_inset Formula $i$
\end_inset

 in the network is activated (i.e.
 that its state 
\begin_inset Formula $s_{i}$
\end_inset

 equals 1) is a sigmoid function of the states 
\begin_inset Formula $s_{j}$
\end_inset

 of its parents 
\begin_inset Formula $j$
\end_inset

, the weights 
\begin_inset Formula $w_{ij}$
\end_inset

 of the directed connections from parent 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $i$
\end_inset

, and the bias 
\begin_inset Formula $b_{i}$
\end_inset

 of node 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\[
P(X_{i}=s_{i}=1)=\frac{1}{1+\exp(-b_{i}-\sum_{j}s_{j}w_{ij})}
\]

\end_inset


\end_layout

\begin_layout Standard
The training algorithm for deep belief networks is a possible solution of
 how to learn a logistic belief network with many hidden layers.
 Learning such a logistic belief network is the task of finding weights
 for the connections and biases for the nodes such that the probability
 of the training samples becomes maximal, and the probabilities for other
 visible layer configurations low.
 A logistic belief network is a directed graphical model of the form as
 show in the example 
\begin_inset CommandInset ref
LatexCommand vref
reference "sub:Example-of-Exact-Inference-in-a-directed-graphical-model"

\end_inset

, and therefore exact inference is intractable, because the probabilities
 of nodes in a hidden layer given the states of nodes in the layer below
 are inter-dependent due to explaining away.
 This makes learning a belief network with multiple hidden layers very hard,
 since the derivative of the probability of the visible layer with respect
 to a specific weight of the network is intractable
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I think it might be because the derivative with respect to a specific
 weight of an outgoing connection depends on the weights of the outgoing
 connections of adjacent nodes in the same layer.
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

 addressed this problem by introducing so-called 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
complementary priors
\end_layout

\end_inset


\emph on
complementary priors
\emph default
.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: explain what these are.
\end_layout

\end_inset

 Using Bayes theorem, the posterior probabilities of the nodes 
\begin_inset Formula $\mathbf{H}$
\end_inset

 in the hidden layer above the visible layer with nodes 
\begin_inset Formula $\mathbf{V}$
\end_inset

 are:
\begin_inset Formula 
\[
P(\mathbf{H}\mid\mathbf{V})=\frac{P(\mathbf{V}\mid\mathbf{H})P(\mathbf{H)}}{P(\mathbf{V})}
\]

\end_inset

The key idea of 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

 was to find priors 
\begin_inset Formula $P(\mathbf{H})$
\end_inset

 of a form so that when multiplied with the likelihood 
\begin_inset Formula $P(\mathbf{V}\mid\mathbf{H})$
\end_inset

, the posterior 
\begin_inset Formula $P(\mathbf{H}\mid\mathbf{V})$
\end_inset

 becomes factorial, i.e.
 can be written as a product over the conditional probabilities 
\begin_inset Formula 
\[
P(\mathbf{H}\mid\mathbf{V})=\prod_{j}P(H_{j}\mid\mathbf{V})
\]

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I should insert here why the posterior is usually not factorial.
 Maybe refer to 
\begin_inset CommandInset ref
LatexCommand vref
reference "sub:Example-of-Exact-Inference-in-a-directed-graphical-model"

\end_inset

.
 The formula to look at is 
\begin_inset Formula 
\begin{eqnarray*}
P(H_{1},H_{2}|V_{1},V_{2}) & = & \frac{P(V_{1},V_{2}|H_{1},H_{2})P(H_{1},H_{2})}{P(V_{1},V_{2})}\\
 & = & \frac{P(V_{1}|H_{1},H_{2})P(V_{2}|H_{1},H_{2})P(H_{1},H_{2})}{Z}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
This is not of the form 
\begin_inset Formula $\prod_{j}P(H_{j}\mid\mathbf{V})$
\end_inset

.
\end_layout

\end_inset

They showed that if the probability distributions are strictly positive,
 i.e.
 
\begin_inset Formula $P(\mathbf{V}\mid\mathbf{H})>0$
\end_inset

 and 
\begin_inset Formula $P(\mathbf{H})>0$
\end_inset

 for every value of 
\series bold

\begin_inset Formula $\mathbf{V}$
\end_inset


\series default
 and 
\begin_inset Formula $\mathbf{H}$
\end_inset

, then only likelihoods of the following form lead to a complementary prior:
\begin_inset Formula 
\[
P(\mathbf{V}\mid\mathbf{H})=\frac{1}{\Omega(\mathbf{H})}\exp\left(\sum_{j}\Phi_{j}(\mathbf{V},H_{j})+\beta(\mathbf{V})\right)
\]

\end_inset

where 
\begin_inset Formula $\Omega(\mathbf{H})$
\end_inset

 is the normalization term.
 The complementary prior then is of the form
\begin_inset Formula 
\[
P(\mathbf{H})=\frac{1}{C}\Omega(\mathbf{H})\exp\mbox{\left(\sum_{j}\alpha_{j}(H_{j})\right)}
\]

\end_inset

where the constant 
\begin_inset Formula $C$
\end_inset

 normalizes 
\begin_inset Formula $P(\mathbf{H})$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Insert the posterior here, to show that it is factorial, which was
 the goal.
\end_layout

\end_inset

 The posterior is as follows and factorial:
\begin_inset Formula 
\begin{eqnarray*}
P(\mathbf{H}\mid\mathbf{V}) & =\\
 & =
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: W
\end_layout

\end_inset


\end_layout

\begin_layout Standard
joint distributions 
\begin_inset Formula $P(\mathbf{V},\mathbf{H})$
\end_inset

 
\end_layout

\begin_layout Standard
TODO: insert that an RBM with visible nodes 
\begin_inset Formula $\mathbf{V}$
\end_inset

 and hidden nodes 
\begin_inset Formula $\mathbf{H}$
\end_inset

 can be viewed as an infinite DAG with tied weights between alternating
 representations of the visible and hidden layer.
 TODO: insert graphics like Figure 3 in 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

.
 This provides a starting point for a training algorithm for deep belief
 networks: Start with a single RBM containing visible nodes 
\begin_inset Formula $\mathbf{V_{0}}$
\end_inset

 and hidden nodes 
\begin_inset Formula $\mathbf{H_{0}}$
\end_inset

 and learn the hidden layer representation of the training data.
 Then copy the visible layer together with the weights, turn the copy upside-dow
n (i.e.
 transpose the weights), and connect this new layer called 
\begin_inset Formula $\mathbf{V_{1}}$
\end_inset

 to the top of the hidden layer.
 This new 3-layer network is then further modified: The undirected weights
 between 
\begin_inset Formula $\mathbf{V_{0}}$
\end_inset

 and 
\begin_inset Formula $\mathbf{H_{0}}$
\end_inset

 are untied and replaced by weights going from 
\begin_inset Formula $\mathbf{V_{0}}$
\end_inset

 to 
\begin_inset Formula $\mathbf{H_{0}}$
\end_inset

 , and weights going from 
\begin_inset Formula $\mathbf{H_{0}}$
\end_inset

 to 
\begin_inset Formula $\mathbf{V_{0}}$
\end_inset

.
 The 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: 
\begin_inset Quotes eld
\end_inset

incorrect
\begin_inset Quotes erd
\end_inset

 hab ich irgendwo gelesen, aber ich weiss nicht mehr wo.
\end_layout

\end_inset

 upward weights serve the purpose of inferring the 
\begin_inset Formula $\mathbf{H_{0}}$
\end_inset

 representation of the data, and the downward weights are part of the model.
\end_layout

\begin_layout Standard
A deep belief network is a model that can be used to generate samples distribute
d like a training data set.
\end_layout

\begin_layout Paragraph
Wake-Sleep Algorithm
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/rbm/wake-sleep.pdf
\begin_inset Quotes erd
\end_inset

 describes the wake-sleep algorithm.
 It says something about a factorial distribution produced by the recognition
 weights (the recognition weights are part of the recognition network; there
 is also the generation network), which has only 
\begin_inset Formula $n$
\end_inset

 parameters instead of 
\begin_inset Formula $2^{n}-1$
\end_inset

.
 It also says that this simplification makes it impossible to 
\begin_inset Quotes eld
\end_inset

capture explaining-away effects
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Plain Layout
It also says 
\begin_inset Quotes eld
\end_inset

Both [PCA and clustering] can be viewed as special cases of the minimum
 description length approach, in which there is only one hidden layer and
 it is unnecessary to distinguish between the recognition and generative
 weights because they are always the same.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Comparison of the Representational Power of Markov Random Fields with Bayesian
 Networks
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO Neal shows in (~/uni/publication/zusammenfassung/rbm/A11 Connectionist
 learning of belief networks.pdf) that Boltzmann Machines and Bayesian Networks
 both have instances of them that are not representable in the other kind
 of graphical model.
 This means that some probability distributions representable in Boltzmann
 Machines do not have representations in Bayesian Networks and vice versa.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Artificial Neural Networks
\end_layout

\begin_layout Paragraph
Hopfield Network
\end_layout

\begin_layout Standard
A Hopfield Network is a deterministic recurrent network with 
\begin_inset Formula $m$
\end_inset

 nodes 
\begin_inset Note Note
status open

\begin_layout Plain Layout
As this is not a stochastic network, I don't think it makes sense to define
 random variables 
\begin_inset Formula $\mathbf{N}=(N_{1},\dots,N_{m})$
\end_inset

.
\end_layout

\end_inset

, each having a binary state 
\begin_inset Formula $n_{i}\in\{0,1\}$
\end_inset

 for all nodes 
\begin_inset Formula $i$
\end_inset

.
 Each node has a connection with all others (but not itself).
 The connection from node 
\begin_inset Formula $N_{i}$
\end_inset

 to node 
\begin_inset Formula $N_{j}$
\end_inset

 is directed and has a real weight 
\begin_inset Formula $w_{ij}\in\mathbb{R}$
\end_inset

.
 (As there is no connection from node 
\begin_inset Formula $i$
\end_inset

 to node 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $w_{ii}=0$
\end_inset

 for all nodes 
\begin_inset Formula $i$
\end_inset

.) There is also a real-valued bias 
\begin_inset Formula $b_{i}\in\mathbb{R}$
\end_inset

 for each node 
\begin_inset Formula $i$
\end_inset

.
 (This means each node has 
\begin_inset Formula $m-1$
\end_inset

 outgoing connections and 
\begin_inset Formula $m-1$
\end_inset

 incoming connections.)
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Hier fehlt ein Bild von einem Hopfield-Netzwerk: Die connections sollten
 directed sein, d.h.
 Pfeile am Ende haben.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The network is updated asynchronously: At each time point 
\begin_inset Formula $t$
\end_inset

, a node 
\begin_inset Formula $i$
\end_inset

 is chosen at random out of the 
\begin_inset Formula $m$
\end_inset

 possible nodes and it is updated, while all other nodes remain constant.
 The state 
\begin_inset Formula $n_{i}$
\end_inset

 of node 
\begin_inset Formula $i$
\end_inset

 at time point 
\begin_inset Formula $t$
\end_inset

 is denoted 
\begin_inset Formula $n_{i}^{(t)}$
\end_inset

 and depends on the state of all other nodes at time step 
\begin_inset Formula $t-1$
\end_inset

: 
\begin_inset Formula 
\[
n_{i}^{(t)}=f(\sum_{j\neq i}n_{j}^{(t-1)}w_{ji}+b_{i})
\]

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Note that I have added 
\begin_inset Formula $b_{j}$
\end_inset

 here (to be consistent with the rest of this text), while in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset

 the bias is on the right-hand side in eq.
 2: 
\begin_inset Quotes eld
\end_inset


\begin_inset Formula $<U_{i}$
\end_inset


\begin_inset Quotes erd
\end_inset

.
 To make up for this sign change, I also swap signs in the energy (eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Energy of a Hopfield network-1"

\end_inset

) below.
\end_layout

\end_inset

(In Hopfield's formulation in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset

 there is also an external input 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Der Input, der in jedem Zeitschritt auf den Input addiert wird, heißt in
 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset

 
\begin_inset Formula $I_{i}$
\end_inset

.
\end_layout

\end_inset

to each node, constant over all times 
\begin_inset Formula $t$
\end_inset

.
 Because the bias also does not depend on 
\begin_inset Formula $t$
\end_inset

, both are combined into 
\begin_inset Formula $b_{i}$
\end_inset

 here.)
\begin_inset Newline newline
\end_inset

The activation function 
\begin_inset Formula $f$
\end_inset

 is a stepping function
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: there must be a better word instead of 
\begin_inset Quotes eld
\end_inset

stepping function
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset

, with negative values mapped to 0, and positive values mapped to 1: 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: stimmt die Definition von 
\begin_inset Formula $f$
\end_inset

 überhaupt?
\end_layout

\end_inset

 
\begin_inset Formula 
\[
f(x)=\begin{cases}
0 & \mbox{for }x\leq0\\
1 & \mbox{for }x>0
\end{cases}
\]

\end_inset

While this updating rule was described here as asynchronous (i.e.
 at each time step a node is picked at random and its state is updated,
 which is how Hopfield described it in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
page 1: 
\begin_inset Quotes eld
\end_inset

Each neuron samples its input at random times.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

), updating the network synchronously (i.e.
 all nodes are updated at the same time) is also possible as this is a special
 case of asynchronous updating.
\end_layout

\begin_layout Standard
Although a Hopfield network is recurrent, Hopfield proved that the updating
 rule converges to a (possibly local) minimum given that the weights are
 symmetric (i.e.
 
\begin_inset Formula $w_{ij}=w_{ji}$
\end_inset

) and there are no single-node loops (i.e.
 
\begin_inset Formula $w_{ii}=0$
\end_inset

).
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Aus 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset

: 
\begin_inset Quotes eld
\end_inset

There is a simple mathematical condition which guarantees that the state
 space flow algorithm converges on stable states.
 Any symmetric T with zero diagonal elements (i.e., 
\begin_inset Formula $T_{ij}$
\end_inset

 = 
\begin_inset Formula $T_{ji}$
\end_inset

, 
\begin_inset Formula $T_{ii}$
\end_inset

 = 0) will produce such a flow.
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This can be proven by showing that a single number, associated with the
 state of the network, can only decrease when updating a node.
 It is the so-called 
\emph on
energy 
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
energy
\end_layout

\end_inset

 
\begin_inset Formula $E$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
E^{(t)}=-\frac{1}{2}\sum_{i}\sum_{j\neq i}w_{ij}n_{i}^{(t)}n_{j}^{(t)}-\sum_{i}b_{i}n_{i}^{(t)}\label{eq:Energy of a Hopfield network}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Each update of a single node either doesn't change the energy 
\begin_inset Formula $E$
\end_inset

 or decreases it.
 (Shown in the appendix 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: insert link to file 
\begin_inset Quotes eld
\end_inset

~/uni/publication/zusammenfassung/hopfield-deriv.lyx
\begin_inset Quotes erd
\end_inset

 when the document is finished.
\end_layout

\end_inset

.) As time progresses, 
\begin_inset Formula $E$
\end_inset

 becomes smaller and smaller, i.e.
 
\begin_inset Formula $E^{(t)}\leq E^{(t-1)}$
\end_inset

.
\end_layout

\begin_layout Standard
Training a Hopfield network is the task of finding weights 
\begin_inset Formula $w_{ij}$
\end_inset

 and biases 
\begin_inset Formula $b_{i}$
\end_inset

, so that desirable states (training patterns) have a low energy and undesirable
 states have a high energy.
 Due to this property Hopfield networks can be used as 
\emph on
associative memory
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
associative memory
\end_layout

\end_inset

.
 After training, a Hopfield network can be initialized with a distorted
 pattern, in which the state of some nodes is swapped.
 After iteratively updating until its state doesn't change anymore, the
 stationary state will be equal to a similar pattern used in training if
 training was successful.
\end_layout

\begin_layout Paragraph
Multilayer Perceptron
\end_layout

\begin_layout Standard
A Multilayer Perceptron belongs to the class of deterministic feedforward
 neural networks.
 Feedforward networks are in contrast to recurrent networks, which contain
 a directed cycle of neural connections.
\end_layout

\begin_layout Paragraph
Multilayer feedforward networks as universal function approximators
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HornikWhite1989"

\end_inset

 found that artificial feedforward neural networks with as few as one hidden
 layer are capable of modeling virtually any function within a given error,
 provided the following conditions are met:
\end_layout

\begin_layout Itemize
The activation function must be a 
\begin_inset Quotes eld
\end_inset

squashing
\begin_inset Quotes erd
\end_inset

 function: A squashing function 
\begin_inset Formula $s(x)$
\end_inset

 must be non-decreasing, 
\begin_inset Formula $\lim_{x\rightarrow-\infty}s(x)=0$
\end_inset

 and 
\begin_inset Formula $\lim_{x\rightarrow\infty}s(x)=1$
\end_inset

.
\end_layout

\begin_layout Itemize
Sufficiently many hidden nodes must be available.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HornikWhite1989"

\end_inset

 also note that 
\begin_inset Quotes eld
\end_inset

This [result] implies that any lack of success in applications must arise
 from inadequate learning, insufficient numbers of hidden units or the lack
 of a deterministic relationship between input and target.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Section
Distinction between a deterministic and stochastic network
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: maybe move the definition of a deterministic network and a stochastic
 network somewhere else.
\end_layout

\end_inset

The difference between a stochastic and a deterministic network is that
 in a deterministic network a node represents a single value, while in a
 stochastic network a single node represents a probability distribution.
 In particular, if there is a set of 
\begin_inset Quotes eld
\end_inset

output
\begin_inset Quotes erd
\end_inset

 nodes, then in a deterministic setting the output can be interpreted as
 a single point in a high-dimensional space, while in a stochastic network
 the output is the joint probability distribution over all the random variables
 associated with the output nodes.
\end_layout

\begin_layout Standard
A stochastic network is more general than its deterministic counterpart,
 since a stochastic network can be converted to a deterministic network,
 but not vice-versa.
 This greater generality comes at a higher cost, however, since inference
 and learning in stochastic networks takes longer than the computation of
 the output and the learning in deterministic networks.
\end_layout

\begin_layout Section
Restricted Boltzmann Machines
\end_layout

\begin_layout Paragraph
Boltzmann Machines
\end_layout

\begin_layout Standard
What are Boltzmann Machines? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Example figure of a BM.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A Boltzmann Machine is the stochastic equivalent to a Hopfield network.
 
\end_layout

\begin_layout Paragraph
Inference in Boltzmann Machines
\end_layout

\begin_layout Standard
How is inference complicated in general Boltzmann Machines?
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In 
\begin_inset Quotes eld
\end_inset

Connectionist learning for belief networks
\begin_inset Quotes erd
\end_inset

 (~/uni/publication/zusammenfassung/rbm/A11 Connectionist learning of belief
 networks.pdf), Neal derives the learning rule for Boltzmann Machines: page
 6, equation 7.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Connections to other Graphical Models
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Generalized to allow J and H to vary from spin to spin, and to allow interaction
s between any two spins, the Ising model becomes the 
\begin_inset Quotes eld
\end_inset

Boltzmann machine
\begin_inset Quotes erd
\end_inset

 of Ackley, Hinton, and Sejnowski.
\begin_inset Quotes erd
\end_inset

 [Probabilistic Inference Using Markov Chain Monte Carlo Methods, Radford
 M.
 Neal 1993]
\end_layout

\begin_layout Paragraph
Restricted Boltzmann Machines
\end_layout

\begin_layout Standard
What are Restricted Boltzmann Machines? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Example figure of an RBM.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A Restricted Boltzmann Machine has a bipartite topology: there are visible
 nodes and hidden nodes, and each node in the visible layer is connected
 (via an undirected edge) to all hidden nodes, but there are no visible-to-visib
le node connections and no hidden-to-hidden node connections.
\end_layout

\begin_layout Standard
As originally proposed by Hinton 
\begin_inset Note Note
status open

\begin_layout Plain Layout
and ...
 the guy who named it 
\begin_inset Quotes eld
\end_inset

Harmonium
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

, a Restricted Boltzmann Machine has binary visible and hidden nodes.
 There are extensions to real-valued nodes, however.
\end_layout

\begin_layout Paragraph
Analogy to Hopfield Networks
\end_layout

\begin_layout Standard
A Restricted Boltzmann Machine is a stochastic version of a Hopfield network.
 When choosing a zero temperature 
\begin_inset Formula $T=0$
\end_inset

, the Restricted Boltzmann Machine becomes deterministic and equivalent
 to a Hopfield network.
\end_layout

\begin_layout Standard
The energy of a hopfield network was defined in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Energy of a Hopfield network-1"

\end_inset

 (
\begin_inset CommandInset ref
LatexCommand vpageref
reference "eq:Energy of a Hopfield network-1"

\end_inset

) as:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: repeat energy of equation 
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Difficulties in training multi-layer neural networks
\end_layout

\begin_layout Standard
Training a feed-forward neural network with more than 1 hidden layer using
 back-propagation is difficult and usually does not succeed.
 When attempting to train such a network, each node in the output layer
 often just outputs the mean value over the training cases, independently
 of the input.
 One problem is that there are many local minima (generated by repeatedly
 adding weighted sigmoid functions) of the implicitly optimized energy function
 during back-propagation.
 Another problem is that in discriminative learning, each training case
 only contributes as many bits to the specification of the parameters of
 the network as needed to specify the label.
\end_layout

\begin_layout Paragraph
RBMs can be interpreted as feed-forward neural networks
\end_layout

\begin_layout Standard
A trained stacked RBM can be reinterpreted as a feed-forward neural network.
 In particular, the weights and biases of a trained stacked RBM can be transferr
ed to a multi-layer feed-forward neural network with the same architecture
 as the stacked RBM, thereby making the stochastic RBM a deterministic neural
 network.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: See 
\begin_inset Quotes eld
\end_inset

An Introduction to Restricted Boltzmann Machines
\begin_inset Quotes erd
\end_inset

 by Asja Fischer and Christian Igel.
 Paragraph starting at 
\begin_inset Quotes eld
\end_inset

It is an important property that single as well as stacked RBMs
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset

 This process is also called 
\emph on
pre-training
\emph default
.
 Furthermore, another neural network (usually only one layer, due to the
 training difficulties of multi-layer neural networks) can be put on top
 of the pre-trained converted RBM, where the final (output) layer has neurons
 corresponding to variables to be predicted.
 The resulting network can be then be fine-tuned, using standard back-propagatio
n, into a configuration that can predict from input variables (input at
 the bottom of the network) the output variables (read off at the top of
 the network).
\end_layout

\begin_layout Paragraph
Learning Rule in Restricted Boltzmann Machines
\end_layout

\begin_layout Standard
Usually, the learning rule includes a 
\begin_inset Quotes eld
\end_inset

momentum
\begin_inset Quotes erd
\end_inset

 term.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Formel hinschreiben
\end_layout

\end_inset

 This term works like a low-pass filter and reduces oscillations during
 learning by smoothing the weight and bias deltas added to the parameters
 of the network.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: maybe the following paragraph should go into Results, not Introduction.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Because the momentum term includes a coefficient that describes the fraction
 of the weights deltas in the previous time step to be added to the current
 weight deltas, it adds another meta-parameter to training.
 Sometimes the coefficient is even changed during training, usually gradually
 increased during the early steps of training to its final value.
 This is to prevent the 
\begin_inset Quotes eld
\end_inset

explosion
\begin_inset Quotes erd
\end_inset

 of the model during training, which happens when the training does not
 converge, and can be caused by a too high momentum coefficient.
\end_layout

\begin_layout Subsection
Parameters of a Restricted Boltzmann Machine
\end_layout

\begin_layout Paragraph
Activation function
\end_layout

\begin_layout Standard
The hidden and visible nodes are a function of the sum of their inputs.
 The function that maps the sum of the inputs of a node to its value is
 called the 
\emph on
activation function
\emph default
.
 There are several activations functions:
\end_layout

\begin_layout Paragraph
Sigmoid activation function
\end_layout

\begin_layout Standard
This is a standard activation function, often used in neural networks.
 It has the property that it is almost linear for inputs around zero, tends
 to 1 as its inputs go to positive infinity and to 0 as inputs go to negative
 infinity.
\begin_inset Formula 
\[
\sigma(x)=\frac{1}{1+e^{-x}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Kurve einer sigmoid-Funktion hier einfügen.
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Binarizing the output of a node
\end_layout

\begin_layout Standard
The output of a node in a Restricted Boltzmann Machine, as orignially proposed,
 is binary (i.e.
 either 0 or 1).
 However the sigmoid activation function outputs continuous values between
 0 and 1.
 Therefore the output of the sigmoid activation function is interpreted
 as the probability that the node outputs value 1, and 0 otherwise.
 In this way the output is sampled from 
\begin_inset Formula $\{0,1\}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Linear units with independent Gaussian noise
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HintonSalakhutdinov2006"

\end_inset

 proposed a way to extend Restricted Boltzmann Machines with only binary
 values to nodes with real values.
\end_layout

\begin_layout Paragraph
Rectified linear activation function
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "NairHinton2010"

\end_inset

 then modified the idea in 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonSalakhutdinov2006"

\end_inset

 to rectified linear units, in which the sampled output of a unit is given
 by 
\begin_inset Formula $\max(0,x+N(0,\sigma(x))$
\end_inset

 where 
\begin_inset Formula $x$
\end_inset

 is the sum of the inputs of the unit, 
\begin_inset Formula $\sigma(x)$
\end_inset

 is the sigmoid function, and 
\begin_inset Formula $N(0,\sigma(x))$
\end_inset

 is normally distributed noise with mean 
\begin_inset Formula $0$
\end_inset

 and variance 
\begin_inset Formula $\sigma(x)$
\end_inset

.
\end_layout

\begin_layout Subsection
Regularizations of Restricted Boltzmann Machines
\end_layout

\begin_layout Paragraph
L1 Weight Decay
\end_layout

\begin_layout Paragraph
L2 Weight Decay
\end_layout

\begin_layout Standard
As 
\begin_inset CommandInset citation
LatexCommand cite
key "FischerIgel2012"

\end_inset

 note, adding an L2 weight decay term to the updating term corresponds to
 assuming a zero-mean Gaussian prior on the parameters.
\end_layout

\begin_layout Paragraph
Sparsity
\end_layout

\begin_layout Paragraph
Dropout
\end_layout

\begin_layout Standard
Dropout is usually combined with weight normalization.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I think weight normalization is described a bit in the dropout paper.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Weight normalization
\end_layout

\begin_layout Subsection
Fine-tuning
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: rename this to 
\begin_inset Quotes eld
\end_inset

Back-propagation
\begin_inset Quotes erd
\end_inset

 and add a small paragraph 
\begin_inset Quotes eld
\end_inset

Fine-tuning
\begin_inset Quotes erd
\end_inset

.
 The term 
\begin_inset Quotes eld
\end_inset

fine-tuning
\begin_inset Quotes erd
\end_inset

 is actually used by 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonTeh2006"

\end_inset

 not for back-propagation, but for the up-down algorithm.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In general, 
\emph on
fine-tuning
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
fine-tuning
\end_layout

\end_inset

 is the use of back-propagation to fine-tune the parameters of a neural
 network.
\end_layout

\begin_layout Standard
It is the adaptation of weights and biases of the network to make its set
 of actual outputs better fit a set of desired outputs for a given set of
 inputs.
 Technically it is just running the network for a given input, observing
 the outputs in the output layer, computing the errors to the desired outputs
 and back-propagating them to adapt the weights and biases between all the
 layers.
 This will make the network output values closer to the desired values next
 time this particular input pattern is given to the network.
 The use of the back-propagation algorithm implies that fine-tuning is a
 supervised learning step and thus prone to overfitting.
\end_layout

\begin_layout Standard
Usually in fine-tuning, the sum of the squared differences
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
sum of squared errors
\end_layout

\end_inset


\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
squared-error sum
\end_layout

\end_inset

 between the desired outputs and the actual outputs in the output layer
 are minimized:
\begin_inset Formula 
\[
\sum_{i}(\hat{x_{i}}-x_{i})^{2}
\]

\end_inset

 where 
\begin_inset Formula $x_{i}$
\end_inset

 is the desired value for node 
\begin_inset Formula $i$
\end_inset

 of the output layer and 
\begin_inset Formula $\hat{x_{i}}$
\end_inset

 is the actual output value of node 
\begin_inset Formula $i$
\end_inset

.
 The minimization is done by computing the derivative of the error of one
 node (which is a function of the outputs of the nodes in the above layer
 and the desired output value) with respect to a particular weight and then
 increasing or decreasing the weight by the computed derivative multiplied
 by the learning rate.
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: formula for the updating in the back-propagation algorithm.
 TODO: cite some paper.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
One can also minimize the cross-entropy error
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
cross-entropy error
\end_layout

\end_inset

:
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: cite something.
 Defined like this in the last line of the leftmost column of 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonSalakhutdinov2006"

\end_inset

.
\end_layout

\end_inset


\begin_inset Formula 
\[
-\sum_{i}p_{i}\log\hat{p_{i}}-\sum_{i}(1-p_{i})\log(1-\hat{p_{i}})
\]

\end_inset

 where 
\begin_inset Formula $p_{i}$
\end_inset

 is the desired output value of node 
\begin_inset Formula $i$
\end_inset

 in the output layer and 
\begin_inset Formula $\hat{p_{i}}$
\end_inset

 is the actual output value output by node 
\begin_inset Formula $i$
\end_inset

.
\end_layout

\begin_layout Section
Motivation for using RBMs on genetic data
\end_layout

\begin_layout Standard
There were successes in visual object/face recognition by RBMs.
 There is a certain similarity of visual data and genetic data like high
 correlation of neighboring pixels and certain genes.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Say something about the time taken to train RBMs.
 Training is linear in the number of training cases, but quadratic in the
 number of features if a multiple-layer neural network is trained and the
 number of features is gradually reduced.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Bibliography
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: make the citations look like 
\begin_inset Quotes eld
\end_inset

[FischerIgel2012]
\begin_inset Quotes erd
\end_inset

, not 
\begin_inset Quotes eld
\end_inset

[1]
\begin_inset Quotes erd
\end_inset

.
 This is probably done using a Bibtex style file?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "zusammenfassung"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_body
\end_document
