#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
fix-cm
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing onehalf
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
Notation
\end_layout

\begin_layout Description
Random
\begin_inset space ~
\end_inset

variable The name of a random variable is written upper-case.
 For example: 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\begin_layout Description
Value
\begin_inset space ~
\end_inset

of
\begin_inset space ~
\end_inset

a
\begin_inset space ~
\end_inset

random
\begin_inset space ~
\end_inset

variable The value of a random variable is written lower-case.
 For example, the value of variable 
\begin_inset Formula $X$
\end_inset

 is written 
\begin_inset Formula $x$
\end_inset

.
\end_layout

\begin_layout Description
Vector Vectors or sets are written in bold font.
 For example, the variable 
\begin_inset Formula $\mathbf{X}$
\end_inset

 could represent the variables 
\begin_inset Formula $\{X_{1},X_{2},X_{3}\}$
\end_inset

.
 And the vector 
\begin_inset Formula $\mathbf{x}$
\end_inset

 could mean the values 
\begin_inset Formula $\{x_{1},x_{2},x_{3}\}$
\end_inset

 of the variables 
\begin_inset Formula $\mathbf{X}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: At the end of the manuscript, I could add a list of 
\emph on
emphasized 
\emph default
terms introduced, together with the page number they were introduced on.
 Die emphasized Terms suche ich wahrscheinlich am besten im LyX-Quelltext.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Graphical Models
\end_layout

\begin_layout Paragraph
Graphs
\end_layout

\begin_layout Standard
A 
\emph on
graph 
\emph default
is a set 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 of nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

 and edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

.
 An edge 
\begin_inset Formula $\mathbf{E}\ni e=(n_{1},n_{2})$
\end_inset

 consists of a pair of nodes 
\begin_inset Formula $n_{1}$
\end_inset

 and 
\begin_inset Formula $n_{2}$
\end_inset

.
 The edges can be directed or undirected (i.e.
 the pair 
\begin_inset Formula $(n_{1},n_{2})$
\end_inset

 can be ordered or unordered).
 If all edges are directed, then the graph is called a 
\emph on
directed graph
\emph default
; if all edges are undirected, then the graph is called a 
\emph on
undirected graph
\emph default
.
\end_layout

\begin_layout Standard
A 
\emph on
directed acyclic graph 
\emph default
(DAG) is a directed graph that does not contain (directed) cycles.
 This means if we start at any node and only go into the direction of the
 edges, it is impossible to reach a node visited earlier.
\end_layout

\begin_layout Standard
A 
\emph on
clique 
\emph default
in an undirected graph is a subset of nodes 
\begin_inset Formula $\mathbf{N_{C}}\subset\mathbf{N}$
\end_inset

, such that every pair of nodes in the clique 
\begin_inset Formula $n_{1},n_{2}\in\mathbf{N_{C}}$
\end_inset

 has an edge in the graph 
\begin_inset Formula $(n_{1},n_{2})\in\mathbf{E}$
\end_inset

.
 A 
\emph on
maximal clique
\emph default
 is a clique where there is no edge that can be added to it so that the
 resulting subset is still a clique.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: add definition of 
\begin_inset Quotes eld
\end_inset

separate
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A set of nodes 
\begin_inset Formula $\mathbf{N_{A}}\subset\mathbf{N}$
\end_inset

 is 
\emph on
separated 
\emph default
from a set of nodes 
\begin_inset Formula $\mathbf{N_{B}}\subset\mathbf{N}$
\end_inset

 by a set of nodes 
\begin_inset Formula $\mathbf{N_{S}}\subset\mathbf{N}$
\end_inset

, if it is impossible to go (along the edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

 of the graph) from a node 
\begin_inset Formula $N_{1}\in\mathbf{N_{A}}$
\end_inset

 to a node 
\begin_inset Formula $N_{2}\in\mathbf{N_{B}}$
\end_inset

 without passing through any of the nodes in 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Graphical Models
\end_layout

\begin_layout Standard
Graphical Models are an encoding of a joint probability distribution with
 the help of a graph.
\end_layout

\begin_layout Standard
In a graphical model, each node of the graph corresponds to a random variable
 of the joint probability distribution, and the dependencies between the
 random variables are encoded in the edges of the graph.
 In addition to the graph structure, probability functions of the elements
 of the structure have to be defined that are equivalent to the target joint
 probability.
 Let's illustrate this with an example.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: hier muss ein Beispiel mit einer Tabelle einer joint probability distribut
ion stehen.
\end_layout

\begin_layout Plain Layout
TODO: Hier eine Figure mit einem DAG und einem MRF.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the following we will consider only variables with discrete values in
 the joint probability distribution.
\end_layout

\begin_layout Paragraph
Directed and Undirected Graphical Models
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I should write somewhere that the edges in a directed graph encode
 the dependence and independence relationships between the random variables.
 TODO: What do the edges encode in an undirected graph?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Graphical models can be directed or undirected.
 Graphical models are based on (directed acyclic or undirected) graphs with
 nodes and edges, where each node corresponds to a random variable, and
 the edges encode relations between random variables.
 Directed acyclic graphical models are also called 
\emph on
Bayesian networks
\emph default
, and undirected graphical models are called 
\emph on
Markov random fields
\emph default
.
\end_layout

\begin_layout Standard
(Besides other types of graphs, there is also a unification of Bayesian
 networks and Markov random fields, i.e.
 a graphical model that can have both directed and undirected edges (subject
 to some restrictions of cycles).
 These networks are called 
\emph on
chain graphs
\emph default
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: reference.
 Referenz zu chain graph ist http://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html
 (
\begin_inset Quotes erd
\end_inset

It is possible to have a model with both directed and undirected arcs, which
 is called a chain graph.
\begin_inset Quotes erd
\end_inset

)
\end_layout

\end_inset

, or 
\emph on
partially directed acyclic graphs
\emph default
.)
\end_layout

\begin_layout Subparagraph
Undirected Graphical Model
\begin_inset CommandInset label
LatexCommand label
name "par:Hammersley-Clifford-theorem"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I should at some point write that in undirected graphical models, the probabilit
y is factored into potentials (written 
\begin_inset Formula $\phi$
\end_inset

), where each factor corresponds to a clique in the undirected graph.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Assume that we want to encode a joint probability distribution 
\begin_inset Formula $P$
\end_inset

 into an undirected graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

.
 We could use for every random variable a node, and connect all nodes with
 all others.
 This 
\emph on
complete graph 
\emph default
encodes no conditional independencies.
 However, to minimize computation time we normally want to get a minimal
 graph that still encodes the joint probability distribution faithfully.
 What properties does 
\begin_inset Formula $P$
\end_inset

 have to fulfill and what does the minimal undirected graph 
\begin_inset Formula $G$
\end_inset

 look like?
\end_layout

\begin_layout Standard
The 
\emph on
Hammersley-Clifford theorem
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Hammersley-Clifford theorem
\end_layout

\end_inset


\emph on
 
\emph default
(
\begin_inset CommandInset citation
LatexCommand cite
key "HammersleyClifford1971"

\end_inset

) is helpful here.
 It states that when we have a vector of random variables 
\begin_inset Formula $\mathbf{X}=\{X_{1},\dots,X_{n}\}$
\end_inset

, its strictly positive joint probability distribution 
\begin_inset Formula $P(\mathbf{X})$
\end_inset

 with 
\begin_inset Formula $P(\mathbf{x})>0$
\end_inset

 for all possible values 
\begin_inset Formula $\mathbf{x}$
\end_inset

 of 
\series bold

\begin_inset Formula $\mathbf{X}$
\end_inset


\series default
, and an undirected graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 with each node corresponding to a random variable (i.e.
 
\begin_inset Formula $\mathbf{N}=\{X_{1},\dots,X_{n}\}$
\end_inset

), then the following statements are equivalent:
\end_layout

\begin_layout Itemize
\begin_inset Formula $P(\mathbf{X})$
\end_inset

 is a 
\emph on
Gibbs distribution
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
Gibbs distribution
\end_layout

\end_inset


\emph on
 
\emph default
that factorizes according to the maximal cliques 
\begin_inset Formula $C_{1},\dots,C_{m}$
\end_inset

 in 
\begin_inset Formula $G$
\end_inset

, i.e.
 
\begin_inset Formula $P(\mathbf{X})=\frac{1}{Z}\phi_{1}(\mathbf{C_{1}})\cdot\dots\cdot\phi_{m}(C_{m})$
\end_inset

 where 
\begin_inset Formula $Z$
\end_inset

 is the 
\emph on
partition function
\emph default
, and 
\begin_inset Formula $\phi_{i}(C_{i})$
\end_inset

 are the 
\emph on
potential functions
\emph default
.
\begin_inset Note Note
status open

\begin_layout Plain Layout
On page 21 of the Hammersley-Clifford paper, the authors define the name
 
\begin_inset Quotes eld
\end_inset

light-coloured potential function
\begin_inset Quotes erd
\end_inset

.
 There, they also define 
\begin_inset Quotes eld
\end_inset

Gibbsian ensemble
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset CommandInset label
LatexCommand label
name "local-Markov-property"

\end_inset

the 
\emph on
local Markov property 
\emph default
holds for the graph 
\begin_inset Formula $G$
\end_inset

 and the joint probability distribution 
\begin_inset Formula $P$
\end_inset

: Given the states of the random variables 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: isn't using 
\begin_inset Formula $\mathbf{N}$
\end_inset

 (
\begin_inset Quotes eld
\end_inset

nodes
\begin_inset Quotes erd
\end_inset

) as a synonym for the random variables 
\begin_inset Formula $\mathbf{X}$
\end_inset

 confusing?
\end_layout

\end_inset


\begin_inset Formula $\mathbf{N_{neighbor}}$
\end_inset

 immediately connected to a node 
\begin_inset Formula $X_{i}$
\end_inset

, 
\begin_inset Formula $X_{i}$
\end_inset

 is conditionally independent from all other nodes 
\begin_inset Formula $\mathbf{N}\backslash\mathbf{N_{neighbor}}$
\end_inset

, i.e.
 
\begin_inset Formula $P(X_{i}|\mathbf{N_{neighbor}})=P(X_{i}|\mathbf{N}\backslash\mathbf{N_{neighbor}})$
\end_inset

, where 
\begin_inset Formula $\mathbf{N}\backslash\mathbf{N_{neighbor}}$
\end_inset

 is the set of nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

 without the neighboring nodes of 
\begin_inset Formula $X_{i}$
\end_inset

.
\end_layout

\begin_layout Itemize
the 
\emph on
global Markov property 
\emph default
holds for the graph 
\begin_inset Formula $G$
\end_inset

 and the joint probability distribution 
\begin_inset Formula $P$
\end_inset

: Given any disjoint subsets 
\begin_inset Formula $\mathbf{N_{A}},\mathbf{N_{B}},\mathbf{N_{S}}\subset\mathbf{N}$
\end_inset

 where 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

 separates the nodes 
\begin_inset Formula $\mathbf{N_{A}}$
\end_inset

 from the nodes 
\begin_inset Formula $\mathbf{N_{B}}$
\end_inset

, and given the states of the random variables of 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

, the nodes 
\begin_inset Formula $\mathbf{N_{A}}$
\end_inset

 are conditionally independent of the nodes 
\begin_inset Formula $\mathbf{N_{B}}$
\end_inset

: 
\begin_inset Formula $P(\mathbf{N_{A}}|\mathbf{N_{S}})=$
\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: look up global Markov property and insert formula here
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: insert graphics illustrating local and global Markov property
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I should include the result of the Hammersley-Clifford theorem here.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This means that when we have a strictly positive joint probability distribution
 
\begin_inset Formula $P$
\end_inset

, we can construct the minimal undirected graph 
\begin_inset Formula $G$
\end_inset

 representing 
\begin_inset Formula $P$
\end_inset

 by starting from the completely connected graph and deleting the edges
 
\begin_inset Formula $E_{12}=(N_{1},N_{2})$
\end_inset

 whose ends are conditionally independent 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: conditionally independent on what? I think that's the crux of being
 NP; we probably have to enumerate all possible separators...?
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
A Markov random field must fulfill the 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: is there a difference between 
\begin_inset Quotes eld
\end_inset

global Markov propery
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Markov property
\begin_inset Quotes erd
\end_inset

? There is the local and the global Markov property.
\end_layout

\end_inset

Markov property.
 That is, a graph 
\begin_inset Formula $G=(\mathbf{N},\mathbf{E})$
\end_inset

 consisting of a given set of nodes 
\begin_inset Formula $\mathbf{N}$
\end_inset

 and edges 
\begin_inset Formula $\mathbf{E}$
\end_inset

 is not a Markov random field if there are any three sets of nodes not fulfillin
g the Markov property.
 This means that for all sets of nodes 
\begin_inset Formula $\mathbf{N_{A}}\subset\mathbf{N}$
\end_inset

 and 
\begin_inset Formula $\mathbf{N_{B}}\subset\mathbf{N}$
\end_inset

 separated by a third set of nodes 
\begin_inset Formula $\mathbf{N_{S}}\subset\mathbf{N}$
\end_inset

 the corresponding random variables in 
\begin_inset Formula $\mathbf{N_{A}}$
\end_inset

 must be conditionally independent from the random variables in 
\begin_inset Formula $\mathbf{N_{B}}$
\end_inset

 given the random variables in the separator 
\begin_inset Formula $\mathbf{N_{S}}$
\end_inset

.
\end_layout

\begin_layout Subparagraph
Example of an Undirected Graph Model
\end_layout

\begin_layout Standard
For example, if there are the three cliques 
\begin_inset Formula $\mathbf{C_{1}}=\{X_{1},X_{2},X_{3}\}$
\end_inset

, 
\begin_inset Formula $\mathbf{C_{2}}=\{X_{3},X_{4}\}$
\end_inset

, and 
\begin_inset Formula $\mathbf{C_{3}}=\{X_{3},X_{5}\}$
\end_inset

, then the joint probability distribution 
\begin_inset Formula $P$
\end_inset

 (also called 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Gibbs distribution
\end_layout

\end_inset

Gibbs distribution) can be written as: 
\begin_inset Formula 
\[
P(X_{1},\dots,X_{5})=\frac{1}{Z}\phi_{1}(\mathbf{C_{1}})\phi_{2}(\mathbf{C_{2}})\phi_{3}(\mathbf{C_{3}})
\]

\end_inset

, where 
\begin_inset Formula $\phi_{1}(\mathbf{C_{1}})=\phi(X_{1},X_{2},X_{3})$
\end_inset

 is the potential function of clique 1 (
\emph on
clique potential
\emph default
), and is a function of the 3 random variables 
\begin_inset Formula $X_{1},X_{2},X_{3}$
\end_inset

 in the clique.
 
\begin_inset Formula $Z$
\end_inset

 is the partition function and must normalize the function so that 
\begin_inset Formula $P$
\end_inset

 is a probability: 
\begin_inset Formula 
\[
Z=\sum_{X_{1},\dots,X_{n}}\phi_{1}(\mathbf{C_{1}})\phi_{2}(\mathbf{C_{2}})\phi_{3}(\mathbf{C_{3}})
\]

\end_inset


\end_layout

\begin_layout Standard
In practice, 
\begin_inset Formula $\phi_{1}(X_{1},X_{2},X_{3})$
\end_inset

 can be represented by a table that has, for each possible combination of
 states of the three random variables, a positive real number.
 For example, if each of the three random variables has two states, then
 the table (with 
\begin_inset Formula $2^{3}$
\end_inset

 entries) could look like this:
\end_layout

\begin_layout Standard
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="4">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x_{3}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\phi(X_{1}=x_{1},X_{2}=x_{2},X_{3}=x_{3})$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.124
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.553
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.842
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\vdots$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.258
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Paragraph
Generative and Discriminative Models
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I'm not sure this belongs here, but I should introduce the concept
 of a 
\begin_inset Quotes eld
\end_inset

Generative Model
\begin_inset Quotes erd
\end_inset

 to be able to refer to it later when introducing Deep Belief Networks from
 RBMs.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Bayesian Networks
\end_layout

\begin_layout Standard
As said before, directed acyclic graphical models are also called 
\emph on
Bayesian Networks
\emph default
 or 
\emph on
Belief Networks
\emph default
.
\end_layout

\begin_layout Paragraph
Inference in Graphical Models
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Do 
\begin_inset Formula $\mathbf{K},\mathbf{W},\mathbf{U}$
\end_inset

 have to fulfill some relationship for directed acyclic graphs in the inference
 example below? (For example, does 
\begin_inset Formula $\mathbf{K}$
\end_inset

 have to be a subset of the parents of 
\series bold

\begin_inset Formula $\mathbf{W}$
\end_inset


\series default
?)
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Exact Inference in Directed and in Undirected Graphical Models
\begin_inset CommandInset label
LatexCommand label
name "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset


\end_layout

\begin_layout Standard
A graphical model is a representation of a joint probability distribution.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I'm not sure I know how 
\begin_inset Quotes eld
\end_inset

Inference
\begin_inset Quotes erd
\end_inset

 is defined.
 I should look it up in a book, e.g.
 
\begin_inset Quotes eld
\end_inset

Probabilistic Graphical Model, by Koller and Friedman
\begin_inset Quotes erd
\end_inset

.
 But that book is not downloadable.
\end_layout

\begin_layout Plain Layout
There is a paper, however: http://ai.stanford.edu/~koller/Papers/Koller+al:SRL07.pd
f
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inference in a graphical model is the task of answering a query about the
 joint probability distribution encoded by the graph.
 However, in the general case this takes exponential time.
 An example will illustrate this.
\end_layout

\begin_layout Standard
For example, we might want to infer the probability of a configuration of
 variables when the values of only some of the variables are known.
 This means that we can partition the variables 
\begin_inset Formula $\mathbf{V}$
\end_inset

 of a graphical model into three disjoint groups:
\end_layout

\begin_layout Enumerate
the known variables 
\begin_inset Formula $\mathbf{K}$
\end_inset

,
\end_layout

\begin_layout Enumerate
the unknown variables 
\begin_inset Formula $\mathbf{W}$
\end_inset

 that we want to know the probability distribution of,
\end_layout

\begin_layout Enumerate
the unknown variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

 that we do not care about.
\end_layout

\begin_layout Standard
Let the known values of 
\begin_inset Formula $\mathbf{K}$
\end_inset

 be written 
\series bold

\begin_inset Formula $\mathbf{k}$
\end_inset


\series default
.
 The unknown values of 
\begin_inset Formula $\mathbf{W}$
\end_inset

 are named 
\series bold

\begin_inset Formula $\mathbf{w}$
\end_inset


\series default
, and the values of 
\begin_inset Formula $\mathbf{U}$
\end_inset

, 
\begin_inset Formula $\mathbf{u}$
\end_inset

.
 
\end_layout

\begin_layout Standard
When we want to find the probability of configuration 
\begin_inset Formula $\mathbf{W}=\mathbf{w}$
\end_inset

, given 
\begin_inset Formula $\mathbf{K}=\mathbf{k}$
\end_inset

, we can first write the query in terms of the joint probability distribution.
 After that we marginalize out the unknown variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

 that we do not care about, and condition on 
\begin_inset Formula $\mathbf{K}$
\end_inset

.
 
\begin_inset Formula 
\begin{eqnarray}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k}) & = & \sum_{\mathbf{U}}P(\mathbf{W}=\mathbf{w},\mathbf{U}=\mathbf{u}|\mathbf{K}=\mathbf{k})\nonumber \\
 & = & \sum_{\mathbf{U}}\frac{P(\mathbf{W}=\mathbf{w},\mathbf{U}=\mathbf{u},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\label{eq:Inference in graphical models}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: write that in the general case, this query is exponential.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the above formula there is a sum over all variables 
\series bold

\begin_inset Formula $\mathbf{U}$
\end_inset


\series default
.
 Writing this out, we obtain: 
\begin_inset Formula 
\begin{eqnarray}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k})\nonumber \\
= & \sum_{\mathbf{U}}\frac{P(\mathbf{W}=\mathbf{w},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\nonumber \\
= & \sum_{U_{1}}\sum_{U_{2}}\cdots\sum_{U_{n}}\frac{P(\mathbf{W}=\mathbf{w},U_{1}=u_{1},U_{2}=u_{2},\dots,U_{n}=u_{n},\mathbf{K}=\mathbf{k})}{P(\mathbf{K}=\mathbf{k})}\label{eq:Inference in graphical models, written out}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
In the general case (if the joint probability cannot be factorized), this
 nested sum needs 
\begin_inset Formula $O(|\mathbf{u}|^{|\mathbf{U}|})=O(|\mathbf{u}|^{n})$
\end_inset

 operations to compute, where 
\begin_inset Formula $|\mathbf{u}|$
\end_inset

 is the number of possible values a variable 
\begin_inset Formula $U_{i}$
\end_inset

 can have (assuming for simplicity that all random variables 
\begin_inset Formula $U_{i}$
\end_inset

 have the same number of possible values 
\begin_inset Formula $|\mathbf{u}|$
\end_inset

) and 
\begin_inset Formula $|\mathbf{U}|$
\end_inset

 is the number of unknown variables 
\begin_inset Formula $U_{i}$
\end_inset

.
 This is because all possible combinations of variable assignments have
 to be considered.
 Thus, run-time is exponential in the number of variables, and therefore
 intractable.
\end_layout

\begin_layout Standard
This can be improved by factorizing the joint probability into independent
 sub-joint-probabilities, if possible.
 For example, if the random variables 
\begin_inset Formula $\mathbf{U}=\{U_{1},U_{2},\dots,U_{7}\}$
\end_inset

 can be partitioned into three pairwise independent cliques 
\begin_inset Formula $\mathbf{C_{1}}=\{U_{1},U_{2}\},$
\end_inset

 
\begin_inset Formula $\mathbf{C_{2}}=\{U_{2},U_{3}\}$
\end_inset

, 
\begin_inset Formula $\mathbf{C_{3}}=\{U_{3},U_{4},U_{5}\}$
\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Note that the random variables 
\begin_inset Formula $U$
\end_inset

 overlap between clusters, so that the clusters are connected.
\end_layout

\end_inset

, so that 
\begin_inset Formula $P(\mathbf{U})=P(\mathbf{C_{1}})P(\mathbf{C_{2}})P(\mathbf{C_{3}})$
\end_inset

, then above sum can be written as: 
\begin_inset Formula 
\begin{eqnarray*}
P(\mathbf{W}=\mathbf{w}|\mathbf{K}=\mathbf{k}) & =\\
 & = & \sum_{\mathbf{C_{1}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{1}}|\mathbf{K}=\mathbf{k})*\\
 &  & \sum_{\mathbf{C_{2}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{2}}|\mathbf{K}=\mathbf{k})*\\
 &  & \sum_{\mathbf{C_{3}}}P(\mathbf{W}=\mathbf{w},\mathbf{C_{3}}|\mathbf{K}=\mathbf{k})\\
 & = & \prod_{\mathbf{C}\in\{\mathbf{C_{1}},\mathbf{C_{2}},\mathbf{C_{3}}\}}\sum_{\mathbf{C}}P(\mathbf{W}=\mathbf{w},\mathbf{C}|\mathbf{K}=\mathbf{k})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
The runtime of this formula is dominated by the largest clique, and so the
 runtime is 
\begin_inset Formula $O(|\mathbf{u}|^{|\mathbf{C_{l}}|})$
\end_inset

, where 
\begin_inset Formula $\mathbf{C_{l}}$
\end_inset

 is the clique with the largest number of variables in it (in our case 
\begin_inset Formula $\mathbf{C_{l}}=\mathbf{C_{3}}$
\end_inset

, because 
\begin_inset Formula $|\mathbf{C_{3}}|=3$
\end_inset

, and 
\begin_inset Formula $|\mathbf{C_{1}}|=|\mathbf{C_{2}}|=2$
\end_inset

).
 This is still an exponential run-time.
 Therefore, in practice, the joint probability is approximated, for example
 by Gibbs sampling.
\end_layout

\begin_layout Subsubsection
Markov Chain
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Bild von einer Markov Chain.
 Evtl.
 von einer Markov Chain, an der ich die verschiedenen Eigenschaften wie
 period, irreducible, etc.
 zeigen kann.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Definitions
\end_layout

\begin_layout Subparagraph
Markov property: Memorylessness
\end_layout

\begin_layout Standard
A 
\emph on
Markov Chain 
\emph default
is a time sequence of random variables 
\begin_inset Formula $X_{t}$
\end_inset

, where 
\begin_inset Formula $t\in\mathbb{N}_{0}$
\end_inset

 denotes the discrete index of time.
 In a Markov Chain, each random variable 
\begin_inset Formula $X_{t}$
\end_inset

 may depend only on the state of the random variable at the immediate previous
 time point 
\begin_inset Formula $t-1$
\end_inset

, i.e.
 
\begin_inset Formula 
\[
P(X_{t}=x_{t}|X_{0}=x_{0},\dots,X_{t-1}=x_{t-1})=P(X_{t}=x_{t}|X_{t-1}=x_{t-1})
\]

\end_inset

must hold for all 
\begin_inset Formula $t\geq1$
\end_inset

.
 This memorylessness is called the 
\emph on
Markov property
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
Markov property
\end_layout

\end_inset

.
 In a Markov Chain, possible states 
\begin_inset Formula $x_{t}$
\end_inset

 at each time point are discrete and from the same set 
\begin_inset Formula $\mathbb{S}$
\end_inset

.
 (I.e.
 
\begin_inset Formula $x_{t}\in\mathbb{S}$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.) When the state a Markov Chain is in is not specific to a certain time
 point 
\begin_inset Formula $t$
\end_inset

, we will also use single-letter variables like 
\begin_inset Formula $i\in\mathbb{S}$
\end_inset

 and 
\begin_inset Formula $j\in\mathbb{S}$
\end_inset

 to denote the state, e.g.
 
\begin_inset Formula $X_{1}=i$
\end_inset

.
\end_layout

\begin_layout Subparagraph
Time-homogeneous Markov Chain and Transition Matrix
\end_layout

\begin_layout Standard
A 
\emph on
time-homogeneous Markov Chain
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
time-homogeneous Markov Chain
\end_layout

\end_inset

 is a Markov Chain in which the conditional probability 
\begin_inset Formula $P(X_{t}=x_{t}|X_{t-1}=x_{t-1})$
\end_inset

 is the same for all time points 
\begin_inset Formula $t$
\end_inset

, i.e.
 
\begin_inset Formula 
\[
P(X_{t}=x_{t}|X_{t-1}=x_{t-1})=P(X_{t-1}=x_{t-1}|X_{t-2}=x_{t-2})
\]

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
for all time points 
\begin_inset Formula $t\geq2$
\end_inset

.
 If this is the case, then this conditional probability
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit

\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: In the following, do I have to replace 
\begin_inset Formula $p$
\end_inset

 with 
\begin_inset Formula $P$
\end_inset

, because it is a matrix?
\end_layout

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula 
\[
P(X_{t}=j|X_{t-1}=i)\eqqcolon p_{ij}
\]

\end_inset

 is independent of the current time 
\begin_inset Formula $t$
\end_inset

 and can be written as the two-dimensional matrix 
\begin_inset Formula $p$
\end_inset

, called the 
\family default
\series default
\shape default
\size default
\emph on
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
transition matrix
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
transition matrix
\end_layout

\end_inset


\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
.
 In the following we will only be dealing with time-homogeneous Markov chains.
\end_layout

\begin_layout Subparagraph
Computing future states from the initial distribution
\end_layout

\begin_layout Standard
It makes sense to talk about the distribution of states a Markov chain can
 have at a certain time point 
\begin_inset Formula $t$
\end_inset

.
 Let it be named the 
\emph on
probability vector
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
probability vector
\end_layout

\end_inset


\emph on
 
\emph default

\begin_inset Formula $d^{(t)}$
\end_inset

, a row vector with its length equal to 
\begin_inset Formula $|\mathbb{S}|$
\end_inset

 (the number of different possible states of the random variables 
\begin_inset Formula $X_{t}$
\end_inset

) and its entry 
\begin_inset Formula $d_{i}^{(t)}=P(X_{t}=x_{i})$
\end_inset

 equal to the probability of 
\begin_inset Formula $X_{t}$
\end_inset

 having state 
\begin_inset Formula $x_{i}$
\end_inset

.
 (This means 
\begin_inset Formula $\sum_{i}d_{i}^{(t)}=1$
\end_inset

 for all 
\begin_inset Formula $t$
\end_inset

.) The distribution at the next time point 
\begin_inset Formula $t+1$
\end_inset

 can be computed by matrix multiplication from 
\begin_inset Formula $d^{(t)}$
\end_inset

 and the transition matrix 
\begin_inset Formula $(p_{ji})$
\end_inset

: 
\begin_inset Formula 
\[
d^{(t+1)}=d^{(t)}p
\]

\end_inset


\end_layout

\begin_layout Standard
Given an initial distribution 
\begin_inset Formula $d^{(0)}$
\end_inset

 and the transition matrix 
\begin_inset Formula $p$
\end_inset

, the probabilities of all states the Markov chain can assume are defined
 for all time points 
\begin_inset Formula $t\geq0$
\end_inset

: 
\begin_inset Formula 
\[
d^{(t)}=d^{(0)}p^{t}
\]

\end_inset

.
\end_layout

\begin_layout Subparagraph
Stationary distribution
\end_layout

\begin_layout Standard
There are time-homogeneous Markov chains whose state distribution stays
 constant once it has assumed a certain state distribution.
 Such state distributions are called 
\emph on
invariant
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
invariant distribution
\end_layout

\end_inset


\emph on
 
\emph default
or 
\emph on
stationary distribution
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
stationary distribution
\end_layout

\end_inset

.
 A stationary distribution 
\begin_inset Formula $\pi$
\end_inset

 must fulfill the following equation: 
\begin_inset Formula 
\[
\pi p=\pi
\]

\end_inset

If 
\begin_inset Formula $d^{(t)}=\pi$
\end_inset

, then 
\begin_inset Formula $d^{(t+u)}=\pi$
\end_inset

 for all 
\begin_inset Formula $u\geq0$
\end_inset

.
 A Markov Chain can have more than one stationary distribution.
\end_layout

\begin_layout Subparagraph
Detailed balance/Reversibility
\end_layout

\begin_layout Standard
A Markov chain with transition matrix 
\begin_inset Formula $p$
\end_inset

 satisfies 
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
detailed balance
\end_layout

\end_inset


\emph on
detailed balance 
\emph default
if there exists a probability distribution 
\begin_inset Formula $\pi=(\pi_{1},\pi_{2},\dots\pi_{n})$
\end_inset

 such that 
\begin_inset Formula 
\[
\pi_{j}p_{ji}=\pi_{i}p_{ij}
\]

\end_inset

.
 Such a Markov chain is also
\begin_inset Note Note
status open

\begin_layout Plain Layout
Is this true? In 
\begin_inset Quotes eld
\end_inset

neal.pdf
\begin_inset Quotes erd
\end_inset

, it says 
\begin_inset Quotes eld
\end_inset

Often, we will use time reversible homogeneous Markov chains that satisfy
 the 
\series bold
more restrictive 
\series default
condition of detailed balance
\begin_inset Quotes erd
\end_inset

.
 So Markov chains satisfying detailed balance seem to be a subset of the
 Markov chains satisfying time reversibility.
\end_layout

\end_inset

 called a 
\emph on
reversible
\emph default
 Markov chain
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
reversible Markov chain
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Norris1997"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Lemma 1.9.3
\end_layout

\end_inset

.
 A Markov chain with the detailed balance property is known to 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: why is detailed balance not enough for a Markov chain to have an unique
 stationary distribution in AltRBM-proof.pdf? why do we need irreducibility
 and aperiodicity?
\end_layout

\begin_layout Plain Layout
irreducibility has to be shown so that we can be sure that the markov chain
 has an unique stationary distribution.
\end_layout

\begin_layout Plain Layout
aperiodicity: 
\begin_inset Quotes eld
\end_inset

AltRBM-proof.pdf
\begin_inset Quotes erd
\end_inset

 says 
\begin_inset Quotes eld
\end_inset

One can show that an irreducible and aperiodic Markov chain on a finite
 state space is guarantied to converge to its stationary distribution (see,
 e.g., [6]).
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

have at least one stationary distribution, where the stationary distributions
 fulfill the 
\begin_inset Formula $\pi$
\end_inset

 from the detailed balance condition 
\begin_inset CommandInset citation
LatexCommand cite
key "Norris1997"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Lemma 1.9.2
\end_layout

\end_inset

.
 While having detailed balance implies that a Markov chain has a stationary
 distribution, the reverse is not true: there are Markov chains with a stationar
y distribution but not satisfying detailed balance.
 (For example, a Markov chain with transition probabilities 
\begin_inset Formula $p_{ij}=p_{jk}=p_{ki}=1$
\end_inset

 for 
\begin_inset Formula $i\neq j$
\end_inset

, 
\begin_inset Formula $j\neq k$
\end_inset

, 
\begin_inset Formula $k\neq i$
\end_inset

, and the other entries of the transition matrix equal to 0 does not satisfy
 detailed balance, but 
\begin_inset Formula $\pi_{i}=\pi_{j}=\pi_{k}=\frac{1}{3}$
\end_inset

 is a stationary distribution of this Markov chain.)
\end_layout

\begin_layout Paragraph
Fundamental Theorem of Markov Chains
\begin_inset CommandInset label
LatexCommand label
name "par:Fundamental-Theorem-of-Markov-Chains"

\end_inset


\end_layout

\begin_layout Standard
Under what conditions does a Markov chain have an unique stationary distribution
? This is answered by the 
\emph on
Fundamental Theorem of Markov Chains
\emph default

\begin_inset Note Note
status open

\begin_layout Plain Layout
which was proved by Kolmogorov?.
 TODO
\end_layout

\end_inset

 (refer to e.g.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

).
 It states that, in the long run (i.e.
 
\begin_inset Formula $\lim_{t\rightarrow\infty}d^{(0)}p^{t}$
\end_inset

), the probability vector converges to the unique stationary distribution
 irrespective of the starting state 
\begin_inset Formula $d^{(0)}$
\end_inset

, given that 
\begin_inset Formula $p$
\end_inset

 is irreducible, positive-recurrent and aperiodic
\begin_inset Note Note
status open

\begin_layout Plain Layout
Theorem 7.4 in ~/uni/publication/zusammenfassung/markov chains/markovbuch2008.pdf.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Irgendwo an passender Stelle einfügen: 
\begin_inset Quotes eld
\end_inset

It is possible to efficiently calculate the stationary distribution 
\begin_inset Formula $\pi$
\end_inset

 by computing only the transition matrix for time steps that are a power
 of 2, i.e.
 
\begin_inset Formula $p^{2^{t}}$
\end_inset

.
 This can be done by repeated squaring and assignment: 
\begin_inset Formula $p^{2t}:=p^{t}p^{t}$
\end_inset

.
 (And starting with 
\begin_inset Formula $p^{1}:=p$
\end_inset

.)
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

.
 The definitions of irreducibility, positive recurrence, and aperiodicity
 follow.
\end_layout

\begin_layout Subparagraph
Irreducibility
\end_layout

\begin_layout Standard
A Markov Chain is called 
\emph on
irreducible
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
irreducible
\end_layout

\end_inset

, if it is possible to go from any state 
\begin_inset Formula $i$
\end_inset

 of the Markov Chain to any state 
\begin_inset Formula $j$
\end_inset

 (possibly in more than 1 steps).
 Formally, a Markov Chain is called irreducible, if its states are all in
 the same (and only) closed subset.
 A subset 
\begin_inset Formula $C$
\end_inset

 of 
\begin_inset Formula $\mathbb{S}$
\end_inset

 is called 
\emph on
closed 
\emph default
if 
\begin_inset Formula $p_{ij}=0$
\end_inset

 whenever 
\begin_inset Formula $i\in C$
\end_inset

 and 
\begin_inset Formula $j\notin C$
\end_inset

.
 (Remember that 
\begin_inset Formula $\mathbb{S}$
\end_inset

 is the set of possible states of the Markov Chain.)
\end_layout

\begin_layout Subparagraph
Positive Recurrence
\end_layout

\begin_layout Standard
A state 
\begin_inset Formula $i$
\end_inset

 of a Markov Chain is 
\emph on
positive recurrent
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
positive recurrent
\end_layout

\end_inset

, if we expect the Markov Chain to take an finite number of steps until
 it is in state 
\begin_inset Formula $i$
\end_inset

 again, when it started in state 
\begin_inset Formula $i$
\end_inset

 at time point 
\begin_inset Formula $0$
\end_inset

.
 To define positive recurrence formally, we have to define auxiliary measures
 first.
 The probability that state 
\begin_inset Formula $j$
\end_inset

 is visited for the first time -- at time step 
\begin_inset Formula $k$
\end_inset

 -- after the Markov Chain had been in state 
\begin_inset Formula $i$
\end_inset

 at time point 
\begin_inset Formula $0$
\end_inset

 is 
\begin_inset Formula 
\[
f_{ij}^{(k)}:=P(X_{1}\neq j,X_{2}\neq j,\dots,X_{k-1}\neq j,X_{k}=j|X_{0}=i)
\]

\end_inset

.
 The probability that state 
\begin_inset Formula $j$
\end_inset

 is ever reached from state 
\begin_inset Formula $i$
\end_inset

 is 
\begin_inset Formula 
\[
f_{ij}^{*}:=\sum_{k=1}^{\infty}f_{ij}^{(k)}
\]

\end_inset

.
 With this, we can define the expected number of steps for the Markov Chain
 to reach state 
\begin_inset Formula $j$
\end_inset

, when starting at state 
\begin_inset Formula $i$
\end_inset

:
\begin_inset Formula 
\[
\mu_{ij}:=\sum_{k=1}^{\infty}kf_{ij}^{(k)}
\]

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
I won't use 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

 for positive recurrence, because he defines (on page 46 of markovbuch2008.pdf)
 
\begin_inset Formula $\mu_{ij}:=\sum_{k=1}^{\infty}kf_{ij}^{(k)}+(1-f_{ij}^{*})\infty$
\end_inset

, which is not defined for 
\begin_inset Formula $f_{ij}^{*}=1$
\end_inset

.
 I don't understand his definition.
\end_layout

\end_inset

.
 This number is also called the 
\emph on
mean recurrence time
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
mean recurrence time
\end_layout

\end_inset

.
 With these definitions, we can define a state to be 
\emph on
transient
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
transient
\end_layout

\end_inset

, positive recurrent, or 
\emph on
null recurrent
\emph default

\begin_inset Index idx
status open

\begin_layout Plain Layout
null recurrent
\end_layout

\end_inset

:
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}<1$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called transient.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called recurrent.
\end_layout

\begin_deeper
\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

 and 
\begin_inset Formula $\mu_{ii}<\infty$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
positive recurrent
\emph default
.
\end_layout

\begin_layout Itemize
If 
\begin_inset Formula $f_{ii}^{*}=1$
\end_inset

 and 
\begin_inset Formula $\mu_{ii}=\infty$
\end_inset

, the state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
null recurrent
\emph default
.
\end_layout

\end_deeper
\begin_layout Standard
It can be proven that when there are finitely many states, there are no
 null recurrent states (see Proposition 7.2.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Behrends2000"

\end_inset

).
\end_layout

\begin_layout Subparagraph
Aperiodicity
\end_layout

\begin_layout Standard
The definition of an 
\emph on
aperiodic
\emph default
 state is shorter.
 The period of a state
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
period of a state
\end_layout

\end_inset

 
\begin_inset Formula $i$
\end_inset

 is defined as the greatest common denominator of the number of time steps
 needed for a Markov chain so that it is possible to be in state 
\begin_inset Formula $i$
\end_inset

 again, after it was in state 
\begin_inset Formula $i$
\end_inset

 before: 
\begin_inset Formula 
\[
period(i)=gcd(\{k|k\geq0,p_{ii}^{k}>0\})
\]

\end_inset

.
 If 
\begin_inset Formula $period(i)=1$
\end_inset

, state 
\begin_inset Formula $i$
\end_inset

 is called 
\emph on
aperiodic
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
aperiodic
\end_layout

\end_inset

.
 If all states of a Markov chain are aperiodic, the Markov chain is called
 aperiodic.
\end_layout

\begin_layout Subparagraph
Markov Chain Monte Carlo (MCMC)
\end_layout

\begin_layout Standard

\emph on
Markov Chain Monte Carlo
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Markov Chain Monte Carlo
\end_layout

\end_inset

 is a type of algorithm to sample from a multivariate probability distribution.
 A Markov Chain has to be set up so that it 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: And also write down how the target distribution is specified.
 At this point I think that this depends on the specific instance of MCMC,
 e.g.
 Gibbs Sampling needs conditional probabilities.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Gibbs Sampling
\end_layout

\begin_layout Standard

\emph on
Gibbs Sampling
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
Gibbs Sampling
\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "GemanGeman1984"

\end_inset


\emph on
 
\emph default
is an instance of a Markov Chain Monte Carlo (MCMC) algorithm.
 Its goal is to generate samples from a multivariate joint probability distribut
ion.
 The generated samples can then be used to compute an approximation of the
 mean of a distribution, for example.
\end_layout

\begin_layout Standard
To use a Gibbs Sampler, one must construct a Markov chain with its (only)
 stationary distribution equal to the target distribution.
 Because its goal is to sample from a multivariate probability distribution,
 each of the random variables are updated in turn, based on the conditional
 probabilities.
\end_layout

\begin_layout Subparagraph
Gibbs Sampling Requires Closed-form Conditional Probabilities
\end_layout

\begin_layout Standard
This means that a precondition to being able to use a Gibbs Sampler is that
 the following conditional probabilities of the target distribution are
 known, so that they can be evaluated.
 Suppose that the multivariate target distribution is 
\begin_inset Formula $P(X_{1},\dots,X_{n})$
\end_inset

.
 Then for each random variable 
\begin_inset Formula $X_{i}\in\{X_{1},\dots,X_{n}\}$
\end_inset

 the conditional probability of the variable given all other variables must
 be known in closed form: 
\begin_inset Formula 
\[
P(X_{i}|\mathbf{X_{j}},j\in\{1,\dots,n\}\backslash i)=P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},X_{n})
\]

\end_inset

It should also be faster to sample from these conditional probability distributi
ons than from the joint target probability distribution, because otherwise
 one should just sample from the joint distribution directly, and not use
 Gibbs sampling.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: hier schreiben, dass die Markov-Kette aus dem Produkt der einzelnen
 Variable-Updates (
\begin_inset Quotes eld
\end_inset

base transitions
\begin_inset Quotes erd
\end_inset

) gebildet wird.
 Siehe Neal93, Kapitel 4.1 (Seite 47).
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Neal schreibt auf Seite 44 ganz unten: 
\begin_inset Quotes eld
\end_inset

For example, each 
\begin_inset Formula $B_{k}$
\end_inset

 might change only some subset of the variables making up the state.
\begin_inset Quotes erd
\end_inset

 Also definiert er anscheinend Markov-Ketten mit mehrdimensionalem state
 vector?
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Gibbs Sampling using a Markov Chain
\end_layout

\begin_layout Standard
The variable updates in Gibbs sampling can be regarded as a Markov chain.
 However, we must first define how the random variables of Gibbs sampling
 are mapped to the random variable of the Markov chain.
 One theoretic possibility is to re-map the random variables and their states
 to a single random variable.
\end_layout

\begin_layout Standard
Above, Markov chains were defined for a single state variable 
\begin_inset Formula $X$
\end_inset

.
 But in Gibbs sampling there are usually more than one variable, written
 
\begin_inset Formula $X_{i}\in\{X_{1},\dots,X_{n}\}$
\end_inset

 above.
 If there are a finite number of random variables in Gibbs sampling, i.e.,
 if 
\begin_inset Formula $n$
\end_inset

 is finite, and the state space of these variables is also finite, say of
 size 
\begin_inset Formula $m$
\end_inset

, then the (therefore also finite) number of states of these variables can
 be encoded in a single variable with a state space of size 
\begin_inset Formula $m^{n}$
\end_inset

.
\begin_inset Note Note
status open

\begin_layout Plain Layout
e.g.
 let's say there are 3 variables, each of which can assume 2 states.
 and i want to encode these 
\begin_inset Formula $2^{3}$
\end_inset

 different possible states in 1 variable.
 then I have 1 variable with 
\begin_inset Formula $2*2*2$
\end_inset

 different possible states.
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Constructing a Markov Chain from Base Transitions
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 suggests
\begin_inset Note Note
status open

\begin_layout Plain Layout
on page 45
\end_layout

\end_inset

 constructing a time-homogeneous Markov Chain from a weighted mixture of
 base transitions, each of which describe the probability of a state change
 of one random variable.
 The base transitions are named 
\begin_inset Formula $B_{k}(x,x')$
\end_inset

, where 
\begin_inset Formula $k$
\end_inset

 is the number of the base transition, 
\begin_inset Formula $x$
\end_inset

 is the starting state of the transition, 
\begin_inset Formula $x'$
\end_inset

 is the target state of the transition, and the whole term 
\begin_inset Formula $B_{k}(x,x')$
\end_inset

 is the probability of the transition.
 A weighted mixture can then be constructed as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
T(\mathbf{x},\mathbf{x}')=\sum_{k}\alpha_{k}B_{k}(x,x')
\]

\end_inset

 where 
\begin_inset Formula $\alpha_{k}$
\end_inset

 is the weight of base transition 
\begin_inset Formula $B_{k}$
\end_inset

, and the weights must fulfill 
\begin_inset Formula $\alpha_{k}>0$
\end_inset

 and 
\begin_inset Formula $\sum_{k}\alpha_{k}=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

 also notes that the required properties are fulfilled: If each of the base
 transitions 
\begin_inset Formula $B_{k}$
\end_inset

 have the same stationary distribution, then the mixture 
\begin_inset Formula $T$
\end_inset

 also has this stationary distribution.
 In addition, if each of the base transitions satisfy detailed balance,
 then the mixture also does.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Hier fehlt wie die Markov Chain genau aussehen muss.
 Wie werden die random variables des Gibbs sampling auf die eine random
 variable der Markov chain gemappt? Wie wird sichergestellt, dass die Markov
 Chain konvergiert?
\end_layout

\begin_layout Plain Layout
Hier muss stehen, dass die Markov Chain nur dann konvergiert, wenn alle
 probabilities strictly positive sind (i.e.
 nicht 0).
 (Siehe 
\begin_inset CommandInset citation
LatexCommand cite
key "Neal1993"

\end_inset

, Seite 48: 
\begin_inset Quotes eld
\end_inset

...
 provided that all the conditional probabilities used to define the B k
 in equation (4.1) are non-zero.
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Plain Layout
Ich glaube in 
\begin_inset CommandInset citation
LatexCommand cite
key "FischerIgel2012"

\end_inset

 steht das auch.)
\end_layout

\end_inset


\end_layout

\begin_layout Subparagraph
Initialization of the Gibbs Sampler
\end_layout

\begin_layout Standard
A Gibbs Sampler starts by specifying a start value 
\begin_inset Formula $x_{i}^{(0)}$
\end_inset

 for each random variable 
\begin_inset Formula $X_{i}$
\end_inset

.
 Since the Markov chain must be constructed such that it converges to its
 only stationary distribution the choice of start values is not critical,
 but it influences the numbers of iterations needed until the Gibbs Sampler
 returns samples from the target distribution.
 So the start value should be close to the 
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

 of the distribution.
\end_layout

\begin_layout Subparagraph
Iterations
\end_layout

\begin_layout Standard
Then an iterative process is started.
 In each iteration 
\begin_inset Formula $t$
\end_inset

, each random variable 
\begin_inset Formula $X_{i}$
\end_inset

 is updated by sampling a new value 
\begin_inset Formula $x_{i}^{(t)}$
\end_inset

 from the conditional probability distribution 
\begin_inset Formula 
\begin{equation}
P(X_{i}|X_{1}=x_{1}^{(t-1)},\dots,X_{i-1}=x_{i-1}^{(t-1)},X_{i+1}=x_{i+1}^{(t-1)},\dots,X_{n}=x_{n}^{(t-1)})\label{eq:Gibbs sampling: CPD}
\end{equation}

\end_inset

.
 Then all the other variables must be updated.
\end_layout

\begin_layout Standard
There are different alternative ways in which the random variables are updated,
 for example updating the random variables can be done in random order,
 or sequentially, or a whole 
\begin_inset Quotes eld
\end_inset

block
\begin_inset Quotes erd
\end_inset

 of multiple random variables can be sampled from the conditional distribution
 given all the other random variables (e.g.
 
\begin_inset Formula $P(X_{i_{1}},X_{i_{2}},X_{i_{3}}|\mathbf{X_{j}=x_{j}^{(t-1)}},j\in\{1,\dots,n\}\backslash\{i_{1},i_{2},i_{3}\})$
\end_inset

).
\end_layout

\begin_layout Standard
If the Markov chain fulfills irreducibility, positive recurrence, and aperiodici
ty, then it is guaranteed to converge to its stationary distribution (see
 
\begin_inset CommandInset ref
LatexCommand vref
reference "par:Fundamental-Theorem-of-Markov-Chains"

\end_inset

).
 However there is currently no known method to determine when the Markov
 chain has done so, which leads to the following two practices, 
\emph on
burn-in
\emph default
 and 
\emph on
thinning
\emph default
.
\end_layout

\begin_layout Subparagraph
Burn-in Period
\end_layout

\begin_layout Standard
The starting value of the random variable might be far from the 
\begin_inset Quotes eld
\end_inset

center
\begin_inset Quotes erd
\end_inset

 of the distribution.
 But after some number of throw-away iterations, the Gibbs Sampler's values
 
\begin_inset Formula $\mathbf{x}=(x_{1},\dots,x_{n})$
\end_inset

 will start coming from the target joint distribution 
\begin_inset Formula $P(X_{1},\dots,X_{n})$
\end_inset

.
 This 
\begin_inset Quotes eld
\end_inset

some number of throw-away iterations
\begin_inset Quotes erd
\end_inset

 is called the 
\emph on
burn-in period
\emph default

\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
burn-in period
\end_layout

\end_inset

 and can be considerable depending on the starting values and the joint
 probability distribution underlying the conditional probability distributions.
\end_layout

\begin_layout Standard
There is no known analytic method to determine when a chain is burned-in.
 One can only use methods like TODO
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

 to determine that a chain is probably 
\emph on
not 
\emph default
burned-in.
\end_layout

\begin_layout Subparagraph
Thinning
\end_layout

\begin_layout Standard
\begin_inset Index idx
status collapsed

\begin_layout Plain Layout
thinning
\end_layout

\end_inset

Even after the Markov chain is burned in, there is still a problem with
 the returned samples, which prevent them from being used in those applications
 needing 
\emph on
independent 
\emph default
samples.
 The samples of two adjacent time steps 
\begin_inset Formula $\mathbf{x}^{(t)}$
\end_inset

 and 
\begin_inset Formula $\mathbf{x}^{(t+1)}$
\end_inset

 are correlated however because the latter is dependent on the former (by
 definition).
\end_layout

\begin_layout Standard
This can be mitigated by returning only the states of every 
\emph on

\begin_inset Formula $n$
\end_inset


\emph default
th iteration, where 
\begin_inset Formula $n$
\end_inset

 is a sufficiently large number.
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: is this true?
\end_layout

\end_inset

 This is called 
\begin_inset Quotes eld
\end_inset

thinning
\begin_inset Quotes erd
\end_inset

 of the Gibbs sampler.
 There is however currently no straightforward way to determine what a sufficien
tly large 
\begin_inset Formula $n$
\end_inset

 is for the adjacent 
\begin_inset Formula $\mathbf{x}$
\end_inset

 to be regarded independent (aside from heuristics like autocorrelation).
\end_layout

\begin_layout Subsubsection
Inference in Markov Random Fields
\end_layout

\begin_layout Paragraph
Gibbs Sampling in Markov Random Fields
\end_layout

\begin_layout Standard
In 
\begin_inset CommandInset ref
LatexCommand vref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

 we described how exact inference in Markov Random Fields can be done by
 conditioning on the known random variables and marginalizing out the uninterest
ing variables.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

 stated that the exponential runtime of exact inference can be circumvented
 by approximate methods like Gibbs sampling.
 Here we address that claim.
\end_layout

\begin_layout Standard
The random variables of the Markov Random Field will be named like those
 in 
\begin_inset CommandInset ref
LatexCommand ref
reference "par:Exact-Inference-in-Directed-and-Undirected Graphical Models"

\end_inset

.
 The interesting variables are named 
\begin_inset Formula $\mathbf{W}$
\end_inset

, the variables whose states are known (for example because they were measured)
 
\begin_inset Formula $\mathbf{K}$
\end_inset

, and the variables we are not interested in 
\begin_inset Formula $\mathbf{U}$
\end_inset

.
 The union of all random variables is called 
\begin_inset Formula $\mathbf{X}:=\{\mathbf{U},\mathbf{K},\mathbf{W}\}$
\end_inset

.
\end_layout

\begin_layout Standard
Gibbs Sampling in Markov Random Fields uses a converging Markov chain to
 sample from the target joint probability distribution.
\end_layout

\begin_layout Enumerate
A prerequisite is that the conditional probability distributions are known
 in closed form.
\end_layout

\begin_layout Enumerate
Initialize the state 
\begin_inset Formula $x_{i}^{(1)}$
\end_inset

 of the random variable 
\begin_inset Formula $X_{i}\in\{\mathbf{W},\mathbf{U}\}$
\end_inset

 with an arbitrary value.
\end_layout

\begin_layout Enumerate
Initialize the state 
\begin_inset Formula $x_{i}^{(1)}$
\end_inset

 of the known random variables 
\begin_inset Formula $X_{i}\in\mathbf{K}$
\end_inset

 with their known state.
\end_layout

\begin_layout Enumerate
\begin_inset CommandInset label
LatexCommand label
name "enu:For-each-time"

\end_inset

For each time point 
\begin_inset Formula $t\in\{2,\dots\}$
\end_inset

 do
\end_layout

\begin_deeper
\begin_layout Enumerate
Keep the known variables fixed (i.e.
 
\begin_inset Formula $x_{i}^{(t+1)}:=x_{i}^{(t)}$
\end_inset

 for all 
\begin_inset Formula $X_{i}\in\mathbf{K}$
\end_inset

).
\end_layout

\begin_layout Enumerate
For each random variable 
\begin_inset Formula $X_{i}\in\{\mathbf{W},\mathbf{U}\}$
\end_inset

 do
\end_layout

\begin_deeper
\begin_layout Enumerate
Given the states of all variables 
\begin_inset Formula $\mathbf{X}\backslash X_{i}$
\end_inset

, sample a new 
\begin_inset Formula $X_{i}$
\end_inset

 from its conditional distribution 
\begin_inset Formula $P(X_{i}=x_{i}^{(t+1)}|X_{1}=x_{1}^{(t)},\dots,X_{i-1}=x_{i-1}^{(t)},X_{i+1}=x_{i+1}^{(t)},\dots,X_{n}=x_{n}^{(t)})$
\end_inset

.
 Due to the Hammersley-Clifford theorem
\begin_inset CommandInset ref
LatexCommand eqref
reference "par:Hammersley-Clifford-theorem"

\end_inset

 this conditional probability is equal to 
\begin_inset Formula $P(X_{i}=x_{i}^{(t+1)}|\mathbf{X}_{Neighborhood(X_{i})})$
\end_inset

.
\end_layout

\end_deeper
\end_deeper
\begin_layout Enumerate
Repeat (
\begin_inset CommandInset ref
LatexCommand ref
reference "enu:For-each-time"

\end_inset

) until the Markov chain converges.
\end_layout

\begin_layout Enumerate
Forget the uninteresting random variables 
\begin_inset Formula $\mathbf{U}$
\end_inset

.
\end_layout

\begin_layout Enumerate
Return the states of the interesting random variables 
\begin_inset Formula $\mathbf{W}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Comparison of Gibbs Sampling in Markov Random Fields and Bayesian Networks
\end_layout

\begin_layout Standard
Gibbs Sampling in Markov Random Fields is easier than Gibbs Sampling in
 directed graphical models.
 This is because the conditional probability distributions needed for Gibbs
 Sampling are simpler than those in Bayesian Networks.
 The conditional probability distribution needed in Gibbs Sampling was given
 in equation 
\begin_inset CommandInset ref
LatexCommand vref
reference "eq:Gibbs sampling: CPD"

\end_inset

.
 This conditional probability is particularly simple for Markov Random Fields,
 because of the local Markov property (refer to 
\begin_inset CommandInset ref
LatexCommand vref
reference "local-Markov-property"

\end_inset

): each random variable 
\begin_inset Formula $X_{i}$
\end_inset

 is independent of all other random variables given the states of the neighborin
g random variables.
 This means that in Markov Random Fields, equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:Gibbs sampling: CPD"

\end_inset

 is 
\begin_inset Formula 
\[
P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},\dots,X_{n})=P(X_{i}|\mathbf{X}_{Neighborhood(X_{i})})
\]

\end_inset

.
 For comparison, in Bayesian Networks the conditional probability would
 be 
\begin_inset Formula 
\[
P(X_{i}|X_{1},\dots,X_{i-1},X_{i+1},\dots,X_{n})=P(X_{i}|\mathbf{X}_{MarkovBlanket(X_{i})})
\]

\end_inset

, where 
\begin_inset Formula $\mathbf{X}_{MarkovBlanket(X_{i})}$
\end_inset

 are the random variables in the Markov Blanket of 
\begin_inset Formula $X_{i}$
\end_inset

.
 The Markov Blanket of a random variable is more complicated to compute
 than its neighborhood.
\end_layout

\begin_layout Paragraph
Explaining away
\end_layout

\begin_layout Standard
Directed Acyclic Graphical Models show the phenomenon of 
\begin_inset Quotes eld
\end_inset

explaining away
\begin_inset Quotes erd
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: is there also explaining away in undirected graphs? nope, I don't
 think so.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In a directed graph Explaining away
\end_layout

\begin_layout Paragraph
Comparison of the Representational Power of Markov Random Fields with Bayesian
 Networks
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO Neal shows in (~/uni/publication/zusammenfassung/rbm/A11 Connectionist
 learning of belief networks.pdf) that Boltzmann Machines and Bayesian Networks
 both have instances of them that are not representable in the other kind
 of graphical model.
 This means that some probability distributions representable in Boltzmann
 Machines do not have representations in Bayesian Networks and vice versa.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Artificial Neural Networks
\end_layout

\begin_layout Paragraph
Hopfield Network
\end_layout

\begin_layout Standard
A Hopfield Network is a deterministic recurrent network with nodes 
\begin_inset Note Note
status open

\begin_layout Plain Layout
As this is not a stochastic network, I don't think it makes sense to define
 random variables 
\begin_inset Formula $\mathbf{N}=\{N_{1},\dots,N_{m}\}$
\end_inset

.
\end_layout

\end_inset

, whose states 
\begin_inset Formula $\mathbf{n}=\{n_{1},n_{m}\}$
\end_inset

 are binary, i.e.
 
\begin_inset Formula $n_{i}\in\{0,1\}$
\end_inset

 for all nodes 
\begin_inset Formula $i$
\end_inset

.
 Each node has a connection with all others (but not itself).
 The connection from node 
\begin_inset Formula $N_{i}$
\end_inset

 to node 
\begin_inset Formula $N_{j}$
\end_inset

 is directed and has a real weight 
\begin_inset Formula $w_{ij}\in\mathbb{R}$
\end_inset

.
 (As there is no connection from node 
\begin_inset Formula $i$
\end_inset

 to node 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $w_{ii}=0$
\end_inset

 for all nodes 
\begin_inset Formula $i$
\end_inset

.) There is also a real-valued bias 
\begin_inset Formula $b_{i}\in\mathbb{R}$
\end_inset

 for each node 
\begin_inset Formula $i$
\end_inset

.
 (This means each node has 
\begin_inset Formula $m-1$
\end_inset

 outgoing connections and 
\begin_inset Formula $m-1$
\end_inset

 incoming connections.)
\end_layout

\begin_layout Standard
The network is updated iteratively, this means the states of time step 
\begin_inset Formula $t$
\end_inset

 depend only on the states at time step 
\begin_inset Formula $t-1$
\end_inset

: 
\begin_inset Formula 
\[
n_{j}^{(t)}=f(\sum_{i\in\{1,\dots,m\}\land i\neq j}n_{i}^{(t-1)}w_{ij}+b_{j})
\]

\end_inset


\begin_inset Newline newline
\end_inset

The activation function 
\begin_inset Formula $f$
\end_inset

 is a stepping function
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: there must be a better word instead of 
\begin_inset Quotes eld
\end_inset

stepping function
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset

, with negative values mapped to 0, and positive values mapped to 1: 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: stimmt die Definition von 
\begin_inset Formula $f$
\end_inset

 überhaupt?
\end_layout

\end_inset

 
\begin_inset Formula 
\[
f(x)=\begin{cases}
0 & x\leq0\\
1 & x>0
\end{cases}
\]

\end_inset


\begin_inset Newline newline
\end_inset

While this updating rule was described here as synchronous (i.e.
 all nodes are updated at the same time), the network can also be updated
 asynchronously (i.e.
 at each time step a node is picked at random and its state is updated,
 which is how Hopfield described it in 1984 
\begin_inset CommandInset citation
LatexCommand cite
key "Hopfield1984"

\end_inset

).
\end_layout

\begin_layout Standard
Although a Hopfield network is recurrent, Hopfield 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: citation.
 TODO: stimmt das überhaupt? In 
\begin_inset Quotes eld
\end_inset

Neural networks and physical systems with emergent collective computational
 abilities
\begin_inset Quotes erd
\end_inset

, Hopfield writes: 
\begin_inset Quotes eld
\end_inset

A simple cycle also occurred occasionally
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

The third behavior seen was chaotic wandering in a small region of state
 space.
\begin_inset Quotes erd
\end_inset

 TODO: Ausserdem steht in den beiden Hopfield-Papers nichts über einen Beweis,
 dass das Netzwerk konvergiert.
\end_layout

\end_inset

 proved that the updating rule converges to a (possibly local) minimum.
\end_layout

\begin_layout Standard
This can be also viewed in terms of an energy: Each state 
\begin_inset Formula $\mathbf{N}=\mathbf{n}$
\end_inset

 has an energy 
\begin_inset Formula $E$
\end_inset

 associated with it: 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: complete
\end_layout

\end_inset

 
\begin_inset Formula 
\begin{equation}
E=\sum\label{eq:Energy of a Hopfield network}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset

As time progresses, 
\begin_inset Formula $E$
\end_inset

 becomes smaller and smaller, i.e.
 
\begin_inset Formula $E^{(t)}\leq E^{(t-1)}$
\end_inset

.
\end_layout

\begin_layout Standard
Training a Hopfield network is the task of finding weights 
\begin_inset Formula $w_{ij}$
\end_inset

 and biases 
\begin_inset Formula $b_{i}$
\end_inset

, so that desirable states (training patterns) have a low energy and undesirable
 states have a high energy.
 After training, a Hopfield network can be initialized with a distorted
 pattern (i.e.
 state), and updated iteratively until its state doesn't change anymore.
 This stationary state should then be equal to a similar pattern used in
 training.
 Due to this property Hopfield networks can be used as 
\emph on
associative memory
\emph default
.
\end_layout

\begin_layout Paragraph
Multilayer Perceptron
\end_layout

\begin_layout Standard
A Multilayer Perceptron belongs to the class of feedforward neural networks.
 These are in contrast to recurrent networks, which contain a directed cycle
 of neural connections.
\end_layout

\begin_layout Paragraph
Multilayer feedforward networks as universal function approximators
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HornikWhite1989"

\end_inset

 found that artificial feedforward neural networks with as few as one hidden
 layer are capable of modeling virtually any function within a given error,
 provided the following conditions are met:
\end_layout

\begin_layout Itemize
The activation function must be a 
\begin_inset Quotes eld
\end_inset

squashing
\begin_inset Quotes erd
\end_inset

 function: A squashing function 
\begin_inset Formula $s(x)$
\end_inset

 must be non-decreasing, 
\begin_inset Formula $\lim_{x\rightarrow-\infty}s(x)=0$
\end_inset

 and 
\begin_inset Formula $\lim_{x\rightarrow\infty}s(x)=1$
\end_inset

.
\end_layout

\begin_layout Itemize
Sufficiently many hidden nodes must be available.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HornikWhite1989"

\end_inset

 also note that 
\begin_inset Quotes eld
\end_inset

This [result] implies that any lack of success in applications must arise
 from inadequate learning, insufficient numbers of hidden units or the lack
 of a deterministic relationship between input and target.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Section
Restricted Boltzmann Machines
\end_layout

\begin_layout Paragraph
Boltzmann Machines
\end_layout

\begin_layout Standard
What are Boltzmann Machines? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Example figure of a BM.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Inference in Boltzmann Machines
\end_layout

\begin_layout Standard
How is inference complicated in general Boltzmann Machines?
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In 
\begin_inset Quotes eld
\end_inset

Connectionist learning for belief networks
\begin_inset Quotes erd
\end_inset

 (~/uni/publication/zusammenfassung/rbm/A11 Connectionist learning of belief
 networks.pdf), Neal derives the learning rule for Boltzmann Machines: page
 6, equation 7.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Connections to other Graphical Models
\end_layout

\begin_layout Standard
\begin_inset Quotes eld
\end_inset

Generalized to allow J and H to vary from spin to spin, and to allow interaction
s between any two spins, the Ising model becomes the 
\begin_inset Quotes eld
\end_inset

Boltzmann machine
\begin_inset Quotes erd
\end_inset

 of Ackley, Hinton, and Sejnowski.
\begin_inset Quotes erd
\end_inset

 [Probabilistic Inference Using Markov Chain Monte Carlo Methods, Radford
 M.
 Neal 1993]
\end_layout

\begin_layout Paragraph
Restricted Boltzmann Machines
\end_layout

\begin_layout Standard
What are Restricted Boltzmann Machines? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Example figure of an RBM.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A Restricted Boltzmann Machine has a bipartite topology: there are visible
 nodes and hidden nodes, and each node in the visible layer is connected
 (via an undirected edge) to all hidden nodes, but there are no visible-to-visib
le node connections and no hidden-to-hidden node connections.
\end_layout

\begin_layout Standard
As originally proposed by Hinton 
\begin_inset Note Note
status open

\begin_layout Plain Layout
and ...
 the guy who named it 
\begin_inset Quotes eld
\end_inset

Harmonium
\begin_inset Quotes erd
\end_inset


\end_layout

\end_inset

, a Restricted Boltzmann Machine has binary visible and hidden nodes.
 There are extensions to real-valued nodes, however.
\end_layout

\begin_layout Paragraph
Analogy to Hopfield Networks
\end_layout

\begin_layout Standard
A Restricted Boltzmann Machine is a stochastic version of a Hopfield network.
 When choosing a zero temperature 
\begin_inset Formula $T=0$
\end_inset

, the Restricted Boltzmann Machine becomes deterministic and equivalent
 to a Hopfield network.
\end_layout

\begin_layout Standard
The energy of a hopfield network was defined in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Energy of a Hopfield network"

\end_inset

 (
\begin_inset CommandInset ref
LatexCommand vpageref
reference "eq:Energy of a Hopfield network"

\end_inset

) as:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: repeat energy of equation 
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Explaining away in RBMs
\end_layout

\begin_layout Standard
There could be the problem of 
\begin_inset Quotes eld
\end_inset

explaining away
\begin_inset Quotes erd
\end_inset

 in multi-layer RBMs.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: https://www.quora.com/Why-does-the-phenomenon-of-explaining-away-make-infere
nce-difficult-in-directed-belief-nets?share=1
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Difficulties in training multi-layer neural networks
\end_layout

\begin_layout Standard
Training a feed-forward neural network with more than 1 hidden layer using
 back-propagation is difficult and usually does not succeed.
 This is probably due to the many local minima (
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: visualise or describe in words the many bumps created by adding many
 weighted sigmoid functions.
\end_layout

\end_inset

) of the implicitly optimized energy function during back-propagation.
\end_layout

\begin_layout Paragraph
RBMs can be interpreted as feed-forward neural networks
\end_layout

\begin_layout Standard
A trained stacked RBM can be reinterpreted as a feed-forward neural network.
 In particular, the weights and biases of a trained stacked RBM can be transferr
ed to a multi-layer feed-forward neural network with the same architecture
 as the stacked RBM, thereby making the stochastic RBM a deterministic neural
 network.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
TODO: See 
\begin_inset Quotes eld
\end_inset

An Introduction to Restricted Boltzmann Machines
\begin_inset Quotes erd
\end_inset

 by Asja Fischer and Christian Igel.
 Paragraph starting at 
\begin_inset Quotes eld
\end_inset

It is an important property that single as well as stacked RBMs
\begin_inset Quotes erd
\end_inset

.
\end_layout

\end_inset

 This process is also called 
\emph on
pre-training
\emph default
.
 Furthermore, another neural network (usually only one layer, due to the
 training difficulties of multi-layer neural networks) can be put on top
 of the pre-trained converted RBM, where the final (output) layer has neurons
 corresponding to variables to be predicted.
 The resulting network can be then be fine-tuned, using standard back-propagatio
n, into a configuration that can predict from input variables (input at
 the bottom of the network) the output variables (read off at the top of
 the network).
\end_layout

\begin_layout Paragraph
Learning Rule in Restricted Boltzmann Machines
\end_layout

\begin_layout Standard
Usually, the learning rule includes a 
\begin_inset Quotes eld
\end_inset

momentum
\begin_inset Quotes erd
\end_inset

 term.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Formel hinschreiben
\end_layout

\end_inset

 This term works like a low-pass filter and reduces oscillations during
 learning by smoothing the weight and bias deltas added to the parameters
 of the network.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: maybe the following paragraph should go into Results, not Introduction.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Because the momentum term includes a coefficient that describes the fraction
 of the weights deltas in the previous time step to be added to the current
 weight deltas, it adds another meta-parameter to training.
 Sometimes the coefficient is even changed during training, usually gradually
 increased during the early steps of training to its final value.
 This is to prevent the 
\begin_inset Quotes eld
\end_inset

explosion
\begin_inset Quotes erd
\end_inset

 of the model during training, which happens when the training does not
 converge, and can be caused by a too high momentum coefficient.
\end_layout

\begin_layout Subsection
Parameters of a Restricted Boltzmann Machine
\end_layout

\begin_layout Paragraph
Activation function
\end_layout

\begin_layout Standard
The hidden and visible nodes are a function of the sum of their inputs.
 The function that maps the sum of the inputs of a node to its value is
 called the 
\emph on
activation function
\emph default
.
 There are several activations functions:
\end_layout

\begin_layout Paragraph
Sigmoid activation function
\end_layout

\begin_layout Standard
This is a fairly standard activation function, often used in neural networks.
 It has the property that it is almost linear for inputs around zero, tends
 to 1 as its inputs go to positive infinity and to 0 as inputs go to negative
 infinity.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: Kurve einer sigmoid-Funktion hier einfügen.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As the values of a Restricted Boltzmann Machine, as orignially proposed,
 are binary (i.e.
 either 0 or 1), the output of the sigmoid activation function is used as
 a probability that the output of the node assumes value 1.
 In this way the output is sampled from 
\begin_inset Formula $\{0,1\}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Linear units with independent Gaussian noise
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "HintonSalakhutdinov2006"

\end_inset

 proposed a way to extend Restricted Boltzmann Machines with only binary
 values to nodes with real values.
\end_layout

\begin_layout Paragraph
Rectified linear activation function
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "NairHinton2010"

\end_inset

 then modified the idea in 
\begin_inset CommandInset citation
LatexCommand cite
key "HintonSalakhutdinov2006"

\end_inset

 to rectified linear units, in which the sampled output of a unit is given
 by 
\begin_inset Formula $max(0,x+N(0,\sigma(x))$
\end_inset

 where 
\begin_inset Formula $x$
\end_inset

 is the sum of the inputs of the unit, 
\begin_inset Formula $\sigma(x)$
\end_inset

 is the variance of the input
\end_layout

\begin_layout Subsection
Regularizations of Restricted Boltzmann Machines
\end_layout

\begin_layout Paragraph
L1 Weight Decay
\end_layout

\begin_layout Paragraph
L2 Weight Decay
\end_layout

\begin_layout Standard
As 
\begin_inset CommandInset citation
LatexCommand cite
key "FischerIgel2012"

\end_inset

 note, adding an L2 weight decay term to the corresponds to assuming a zero-mean
 Gaussian prior on the parameters.
\end_layout

\begin_layout Paragraph
Sparsity
\end_layout

\begin_layout Paragraph
Dropout
\end_layout

\begin_layout Standard
Dropout is usually combined with weight normalization.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: I think weight normalization is described a bit in the dropout paper.
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Weight normalization
\end_layout

\begin_layout Section
Motivation for using RBMs on genetic data
\end_layout

\begin_layout Standard
There were successes in visual object/face recognition by RBMs.
 There is a certain similarity of visual data and genetic data like high
 correlation of neighboring pixels and certain genes.
\end_layout

\begin_layout Section
Bibliography
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO: make the citations look like 
\begin_inset Quotes eld
\end_inset

[FischerIgel2012]
\begin_inset Quotes erd
\end_inset

, not 
\begin_inset Quotes eld
\end_inset

[1]
\begin_inset Quotes erd
\end_inset

.
 This is probably done using a Bibtex style file?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "zusammenfassung"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_body
\end_document
